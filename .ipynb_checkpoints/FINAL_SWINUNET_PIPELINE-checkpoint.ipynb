{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Geophysical Full Waveform Inversion\n",
    "### Prepared by Gaurav Khanal\n",
    "### UniversitÃ© CÃ´te d'Azur\n",
    "### July 31, 2025\n",
    "_____________________\n",
    "\n",
    "This is the complete script of the best model and training we had for geophysical full waveform inversion. It was originally a `.py` script because the jobs were run on the `musa` nodes of teh Sophia cluster of Grid5000. Special thanks to Inria (especially the `maasai` team for giving me the experience of using an HPC environment."
   ],
   "id": "5c54a1678e47e157"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Import relevant packages and libraries",
   "id": "a26c3edda66f6b2a"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import sys\n",
    "import copy\n",
    "import logging\n",
    "import datetime\n",
    "import contextlib\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional, Any\n",
    "\n",
    "# Numerical and scientific computing\n",
    "import numpy as np\n",
    "import psutil\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Deep learning frameworks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim.lr_scheduler import (\n",
    "    CosineAnnealingLR,\n",
    "    CosineAnnealingWarmRestarts,\n",
    "    LinearLR,\n",
    "    SequentialLR\n",
    ")\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.profiler\n",
    "from torchvision.transforms import functional as TF\n",
    "\n",
    "# DDP and metrics\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torchmetrics import MeanAbsoluteError, StructuralSimilarityIndexMeasure\n",
    "\n",
    "# Third-party libraries\n",
    "import timm  # For Swin Transformer models\n",
    "from torchinfo import summary  # For model summary\n",
    "from tqdm.auto import tqdm  # Progress bars"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Warning suppressions\n",
    "def suppress_all_warnings():\n",
    "    \"\"\"Suppress all common deep learning framework warnings\"\"\"\n",
    "    # Python warnings\n",
    "    warnings.filterwarnings('ignore')\n",
    "    warnings.filterwarnings('ignore', category=UserWarning)\n",
    "    warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "    warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "\n",
    "    # PyTorch optimizations\n",
    "    try:\n",
    "        import torch\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "    except ImportError:\n",
    "        pass\n",
    "\n",
    "# Apply comprehensive warning suppression\n",
    "suppress_all_warnings()"
   ],
   "id": "15313b50d293a252",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Configurations\n",
    "\n",
    "This section defines a Config class that centralizes all hyperparameters and settings for the entire training pipeline. This makes it easy to manage and modify experimental parameters without digging through the code. The hyperparameters are grouped by type and function; annotations explain their use."
   ],
   "id": "4cd2d570a142a54a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class Config:\n",
    "    \"\"\"\n",
    "    Central configuration class for all model and training parameters.\n",
    "    Provides default values and validation for the experiment setup.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- Paths, Logging & Resuming ---\n",
    "    TRAIN_PATH = Path(\"/tmp/gkhanal-runtime-dir/data/train/openfwi_72x72\")\n",
    "    OUTPUT_DIR = Path(\"/home/gkhanal/fwi_project/fwi_test/swinv2/results/july25\")\n",
    "    EXPERIMENT_NAME = \"SwinV2_FWI_Combined_Loss_LRWarmRestart\"\n",
    "    RESUME_CHECKPOINT = None  # Path to checkpoint file to resume training\n",
    "\n",
    "    # --- Experiment Controls ---\n",
    "    RUN_PROFILER = False            # Enable PyTorch profiler\n",
    "    EXPORT_ONNX = True              # Export final model to ONNX format\n",
    "    USE_LOSS_WEIGHTING = True       # Whether to use class-weighted loss\n",
    "\n",
    "    # --- Model & Architecture ---\n",
    "    MODEL_NAME = 'swinv2_tiny_window8_256.ms_in1k'  # Timm model name\n",
    "    PRETRAINED = True                               # Use pretrained weights\n",
    "    OUTPUT_CHANNELS = 1                             # Output velocity channels\n",
    "    NUM_SOURCES = 5                                 # Number of seismic sources\n",
    "    DECODER_CHANNELS = [512, 256, 128]              # Enhanced decoder channel sizes\n",
    "    DECODER_DROPOUT = 0.2                           # Dropout rate in decoder\n",
    "    USE_ENHANCED_DECODER = True                     # Use enhanced decoder with learned upsampling\n",
    "\n",
    "    # Model dimensions\n",
    "    INPUT_HEIGHT = 72                               # Input seismic data height\n",
    "    INPUT_WIDTH = 72                                # Input seismic data width\n",
    "    OUTPUT_HEIGHT = 70                              # Output velocity model height\n",
    "    OUTPUT_WIDTH = 70                               # Output velocity model width\n",
    "    BACKBONE_INPUT_SIZE = 256                       # Interpolation size for backbone\n",
    "    STEM_CHANNELS = 32                              # Initial stem convolution channels\n",
    "    RGB_CHANNELS = 3                                # RGB channels for backbone input\n",
    "    GROUPNORM_GROUPS = 8                            # GroupNorm groups\n",
    "    SCSE_REDUCTION = 16                             # Default reduction factor in SCSE block\n",
    "\n",
    "    # --- Loss function weights ---\n",
    "    HUBER_LOSS_WEIGHT = 0.4         # Weight for Huber loss\n",
    "    GRAD_LOSS_WEIGHT = 0.55         # Weight for gradient loss\n",
    "    TV_LOSS_WEIGHT = 0.05           # Weight for total variation loss\n",
    "\n",
    "    # --- Training ---\n",
    "    DEVICE = \"cuda\"                 # Default device\n",
    "    USE_AMP = True                  # Automatic Mixed Precision\n",
    "    NUM_EPOCHS = 50                 # Total training epochs\n",
    "    BATCH_SIZE = 256                # Batch size per GPU\n",
    "    ACCUMULATION_STEPS = 1          # Gradient accumulation steps\n",
    "    WEIGHT_DECAY = 1e-4             # Weight decay\n",
    "    GRAD_CLIP_NORM = 1.0            # Gradient clipping norm\n",
    "\n",
    "    # --- Learning Rate Scheduler\n",
    "    LEARNING_RATE = 1.5e-4          # Initial learning rate (increased for stronger restarts)\n",
    "    LR_MIN = 1e-6                   # Minimum learning rate\n",
    "    WARMUP_EPOCHS = 5               # Warmup epochs\n",
    "    WARMUP_LR_START_FACTOR = 0.01   # Starting factor for warmup learning rate\n",
    "\n",
    "    # --- Warm Restarts Configuration\n",
    "    USE_WARM_RESTARTS = True        # Use CosineAnnealingWarmRestarts instead of CosineAnnealingLR\n",
    "    T_0 = 8                         # Initial restart period (shorter for more exploration)\n",
    "    T_MULT = 2                    # Factor to increase T_i after each restart (more gradual)\n",
    "    ETA_MIN_RESTART = 5e-7          # Minimum learning rate for restarts (lower for deeper exploration)\n",
    "    LR_RESTART_DETECTION_THRESHOLD = 2.0   # Threshold for detecting learning rate restarts\n",
    "    LR_RESTART_SECONDARY_THRESHOLD = 1.5   # Secondary threshold for restart detection\n",
    "    LR_RESTART_MIN_INCREASE_RATIO = 10.0   # Minimum increase ratio from bottom for restart detection\n",
    "\n",
    "    # --- Validation, Checkpointing & EMA ---\n",
    "    VALIDATION_SPLIT = 0.20         # Validation set fraction\n",
    "    PATIENCE = 5                    # Early stopping patience\n",
    "    CHECKPOINT_EVERY = 5            # Save checkpoint every N epochs\n",
    "    EMA_DECAY = 0.99                # EMA decay rate\n",
    "\n",
    "    # --- Data ---\n",
    "    RANDOM_SEED = 42                # Random seed for reproducibility\n",
    "    VELOCITY_MIN = 1500.0           # Minimum velocity value (m/s)\n",
    "    VELOCITY_MAX = 4500.0           # Maximum velocity value (m/s)\n",
    "    MAX_RETRIES = 3                 # Max retries in dataset loading\n",
    "    MIN_STD_CLAMP = 1e-6            # Minimum std clamp value for normalization\n",
    "\n",
    "    # --- Training Constants ---\n",
    "    DDP_TIMEOUT_SECONDS = 60        # DDP timeout seconds\n",
    "    VALIDATION_BATCH_MULTIPLIER = 2 # Batch size multiplier for validation\n",
    "    ELASTIC_ALPHA_RANGE = (30, 50)  # Alpha range for elastic deformation\n",
    "    ELASTIC_SIGMA_RANGE = (4, 6)    # Sigma range for elastic deformation\n",
    "    ONNX_OPSET_VERSION = 13         # ONNX opset version\n",
    "\n",
    "    # --- Torch Compile ---\n",
    "    USE_TORCH_COMPILE = False         # Enable torch.compile for model optimization\n",
    "    COMPILE_MODE = \"default\"         # Compile mode: \"default\", \"reduce-overhead\", \"max-autotune\"\n",
    "\n",
    "    # --- Dataloader ---\n",
    "    NUM_WORKERS = 48                # DataLoader workers\n",
    "    PIN_MEMORY = True               # Pin memory for faster transfer\n",
    "    PERSISTENT_WORKERS = True       # Maintain workers between epochs\n",
    "    PREFETCH_FACTOR = 8             # Prefetch batches\n",
    "    MEMORY_WORKERS_RATIO = 2        # GB of memory per worker for optimal worker calculation\n",
    "\n",
    "    # Augmentation configuration classes\n",
    "    class AugmentationToggles:\n",
    "        \"\"\"Toggle switches for different augmentation types\"\"\"\n",
    "        AMP_JITTER = False          # Amplitude jitter\n",
    "        RECEIVER_DROP = False       # Random receiver dropout\n",
    "        GAUSSIAN_NOISE = True       # Add Gaussian noise\n",
    "        VELOCITY_AUG = True         # Velocity scaling\n",
    "        VELOCITY_SMOOTH = False     # Velocity smoothing\n",
    "        FAULT_SIMULATION = False    # Fault simulation\n",
    "        ELASTIC_DEFORM = False      # Elastic deformation\n",
    "\n",
    "    class AugmentationParams:\n",
    "        \"\"\"Parameters for data augmentations\"\"\"\n",
    "        # Noise parameters\n",
    "        NOISE_STD = 0.02            # Std of Gaussian noise\n",
    "        RECEIVER_DROP_PROB = 0.3    # Probability of receiver drop\n",
    "        MAX_RECEIVER_DROPS = 5      # Maximum receivers to drop\n",
    "\n",
    "        # Amplitude jitter\n",
    "        AMP_JITTER_PROB = 0.2       # Probability of amplitude jitter\n",
    "        AMP_JITTER_SCALE = 0.1      # Scale of amplitude variation\n",
    "\n",
    "        # Fault simulation\n",
    "        FAULT_NOISE_PROB = 0.2      # Probability of fault noise\n",
    "        FAULT_NOISE_STRENGTH = 0.1  # Strength of fault displacement\n",
    "\n",
    "        # Velocity augmentations\n",
    "        VEL_AUG_PROB = 0.2          # Probability of velocity scaling\n",
    "        VEL_AUG_SCALE = 0.1         # Scale of velocity variation\n",
    "        VEL_SMOOTH_PROB = 0.2       # Probability of smoothing\n",
    "\n",
    "        # Elastic deformation\n",
    "        ELASTIC_DEFORM_PROB = 0.3   # Probability of elastic deformation\n",
    "        GAUSSIAN_BLUR_KERNEL_MULTIPLIER = 6    # Multiplier for gaussian blur kernel size (6 * sigma + 1)\n",
    "\n",
    "    def validate(self) -> None:\n",
    "        \"\"\"Validate configuration parameters\"\"\"\n",
    "        if not self.TRAIN_PATH.exists():\n",
    "            raise FileNotFoundError(f\"Train path not found: {self.TRAIN_PATH}\")\n",
    "        if self.ACCUMULATION_STEPS > 0 and self.BATCH_SIZE % self.ACCUMULATION_STEPS != 0:\n",
    "            raise ValueError(f\"BATCH_SIZE ({self.BATCH_SIZE}) must be divisible by ACCUMULATION_STEPS ({self.ACCUMULATION_STEPS}) for proper gradient accumulation.\")\n",
    "        if self.NUM_WORKERS < 0:\n",
    "            raise ValueError(f\"NUM_WORKERS must be non-negative, got {self.NUM_WORKERS}\")\n",
    "        if self.BATCH_SIZE <= 0:\n",
    "            raise ValueError(f\"BATCH_SIZE must be positive, got {self.BATCH_SIZE}\")\n",
    "        if self.NUM_EPOCHS <= 0:\n",
    "            raise ValueError(f\"NUM_EPOCHS must be positive, got {self.NUM_EPOCHS}\")"
   ],
   "id": "66c56054452fde65",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize configuration\n",
    "cfg = Config()\n",
    "augs = cfg.AugmentationToggles()\n",
    "aug_params = cfg.AugmentationParams()"
   ],
   "id": "bf9ea7248075e34a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Distributed Data Parallel (DDP) Manager)\n",
    "\n",
    "The DDPManager class encapsulates the logic for setting up and managing distributed training using PyTorch's Distributed Data Parallel (DDP). It provides a seamless fallback to single-GPU training if DDP cannot be initialized."
   ],
   "id": "f0103935efdc2154"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class DDPManager:\n",
    "    \"\"\"\n",
    "    Handles distributed training setup and cleanup.\n",
    "    Automatically falls back to single-GPU mode if DDP initialization fails.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        \"\"\"Initialize DDP environment if available\"\"\"\n",
    "        self.is_ddp = 'WORLD_SIZE' in os.environ and torch.cuda.is_available()\n",
    "\n",
    "        if self.is_ddp:\n",
    "            try:\n",
    "                # Initialize distributed process group\n",
    "                dist.init_process_group(\n",
    "                    backend=\"nccl\",\n",
    "                    timeout=datetime.timedelta(seconds=cfg.DDP_TIMEOUT_SECONDS)\n",
    "                )\n",
    "                self.rank = dist.get_rank()\n",
    "                self.world_size = dist.get_world_size()\n",
    "                device_id = self.rank % torch.cuda.device_count()\n",
    "                self.device = torch.device(f'cuda:{device_id}')\n",
    "                torch.cuda.set_device(device_id)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"DDP initialization failed: {e}. Falling back to single-GPU.\")\n",
    "                self.is_ddp = False\n",
    "                self._setup_single_gpu()\n",
    "        else:\n",
    "            self._setup_single_gpu()\n",
    "\n",
    "    def _setup_single_gpu(self) -> None:\n",
    "        \"\"\"Setup for single-GPU training\"\"\"\n",
    "        self.rank = 0\n",
    "        self.world_size = 1\n",
    "        self.device = torch.device(cfg.DEVICE if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    def cleanup(self) -> None:\n",
    "        \"\"\"Cleanup distributed process group if initialized\"\"\"\n",
    "        if self.is_ddp and dist.is_initialized():\n",
    "            dist.destroy_process_group()\n",
    "\n",
    "    def is_main_process(self) -> bool:\n",
    "        \"\"\"Check if current process is the main process\"\"\"\n",
    "        return self.rank == 0"
   ],
   "id": "fb990d932b870af5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Setup Utilities\n",
    "\n",
    "This section contains a collection of essential helper functions and utility classes that set up the training environment, manage reproducibility, facilitate logging, and perform crucial pre-training validations."
   ],
   "id": "6fa30400961da912"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def set_seed(seed_value: int = cfg.RANDOM_SEED, rank: int = 0) -> None:\n",
    "    \"\"\"\n",
    "    Set random seeds for reproducibility.\n",
    "\n",
    "    Args:\n",
    "        seed_value: Base seed value\n",
    "        rank: Process rank to ensure different seeds across processes\n",
    "    \"\"\"\n",
    "    seed = seed_value + rank\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.benchmark = True"
   ],
   "id": "bbd56c60e1b715aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def seed_worker(worker_id: int) -> None:\n",
    "    \"\"\"Seed numpy and random for DataLoader workers\"\"\"\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ],
   "id": "402880080fadfd87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def setup_logging(log_file: str = 'training.log') -> None:\n",
    "    \"\"\"Configure logging to file and console\"\"\"\n",
    "    log_format = logging.Formatter(\"%(asctime)s [%(levelname)s] - %(message)s\")\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "\n",
    "    # Remove existing handlers\n",
    "    for handler in logger.handlers[:]:\n",
    "        logger.removeHandler(handler)\n",
    "\n",
    "    # File handler\n",
    "    file_handler = logging.FileHandler(log_file)\n",
    "    file_handler.setFormatter(log_format)\n",
    "    logger.addHandler(file_handler)\n",
    "\n",
    "    # Console handler\n",
    "    console_handler = logging.StreamHandler(sys.stdout)\n",
    "    console_handler.setFormatter(log_format)\n",
    "    logger.addHandler(console_handler)"
   ],
   "id": "bb20ebaecaed3ee3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def safe_barrier(ddp_manager: DDPManager, timeout_seconds: int = cfg.DDP_TIMEOUT_SECONDS) -> None:\n",
    "    \"\"\"\n",
    "    A DDP barrier with timeout to prevent hangs.\n",
    "\n",
    "    Args:\n",
    "        ddp_manager: DDPManager instance\n",
    "        timeout_seconds: Maximum time to wait for barrier\n",
    "    \"\"\"\n",
    "    if ddp_manager.is_ddp:\n",
    "        try:\n",
    "            dist.barrier(device_ids=[ddp_manager.rank])\n",
    "        except RuntimeError as e:\n",
    "            logging.error(f\"DDP barrier timed out after {timeout_seconds}s: {e}\")\n",
    "            raise"
   ],
   "id": "343ce01f01daee3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def validate_ddp_setup(ddp_manager: DDPManager) -> None:\n",
    "    \"\"\"Validate DDP communication between processes\"\"\"\n",
    "    if not ddp_manager.is_ddp:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Test communication with all_reduce\n",
    "        tensor = torch.tensor([ddp_manager.rank], device=ddp_manager.device, dtype=torch.float)\n",
    "        dist.all_reduce(tensor, op=dist.ReduceOp.SUM)\n",
    "        expected = float(sum(range(ddp_manager.world_size)))\n",
    "        assert tensor.item() == expected, f\"DDP validation failed: got {tensor.item()}, expected {expected}\"\n",
    "\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(\"DDP communication validated successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"DDP validation failed: {e}\", exc_info=True)\n",
    "        raise"
   ],
   "id": "14935dce8f9674a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def validate_scheduler_config(train_loader: DataLoader) -> None:\n",
    "    \"\"\"Validate warm restart scheduler configuration\"\"\"\n",
    "    if not cfg.USE_WARM_RESTARTS:\n",
    "        return\n",
    "\n",
    "    steps_per_epoch = len(train_loader) // cfg.ACCUMULATION_STEPS\n",
    "    warmup_steps = cfg.WARMUP_EPOCHS * steps_per_epoch\n",
    "    total_steps = cfg.NUM_EPOCHS * steps_per_epoch\n",
    "    remaining_steps = total_steps - warmup_steps\n",
    "    t_0_steps = cfg.T_0 * steps_per_epoch\n",
    "\n",
    "    # Calculate expected restart schedule\n",
    "    restart_steps = []\n",
    "    current_period = t_0_steps\n",
    "    current_step = warmup_steps + current_period\n",
    "\n",
    "    while current_step < total_steps:\n",
    "        restart_steps.append(current_step)\n",
    "        current_period = int(current_period * cfg.T_MULT)\n",
    "        current_step += current_period\n",
    "\n",
    "    logging.info(f\"Warm restart schedule validation:\")\n",
    "    logging.info(f\"  - Total training steps: {total_steps}\")\n",
    "    logging.info(f\"  - Warmup steps: {warmup_steps}\")\n",
    "    logging.info(f\"  - Steps per epoch: {steps_per_epoch}\")\n",
    "    logging.info(f\"  - Initial restart period: {t_0_steps} steps ({cfg.T_0} epochs)\")\n",
    "    logging.info(f\"  - Expected restarts at steps: {restart_steps}\")\n",
    "    logging.info(f\"  - Total expected restarts: {len(restart_steps)}\")\n",
    "\n",
    "    if len(restart_steps) == 0:\n",
    "        logging.warning(\"No restarts will occur with current configuration!\")\n",
    "    elif len(restart_steps) < 2:\n",
    "        logging.warning(\"Only 1 restart scheduled. Consider smaller T_0 for more exploration.\")"
   ],
   "id": "460fac1c6e429e40"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def validate_model_outputs(model: nn.Module, sample_input: torch.Tensor, device: torch.device) -> None:\n",
    "    \"\"\"Validate model produces expected outputs without NaNs\"\"\"\n",
    "    logging.info(\"Performing model output validation...\")\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            output = model(sample_input.to(device))\n",
    "            assert output.shape[-2:] == (cfg.OUTPUT_HEIGHT, cfg.OUTPUT_WIDTH), f\"Expected output shape ending in ({cfg.OUTPUT_HEIGHT},{cfg.OUTPUT_WIDTH}), got {output.shape[-2:]}\"\n",
    "            assert not torch.isnan(output).any(), \"Model produced NaN outputs on sample input\"\n",
    "            assert torch.isfinite(output).all(), \"Model produced non-finite values (inf) on sample input\"\n",
    "        logging.info(\"Model output validation passed.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Model output validation FAILED: {e}\", exc_info=True)\n",
    "        raise"
   ],
   "id": "c5c7e2b97f88fcb8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class AdaptiveAugmentation:\n",
    "    \"\"\"\n",
    "    Dynamically adjusts augmentation strength based on validation performance.\n",
    "\n",
    "    Attributes:\n",
    "        strength: Current augmentation strength multiplier\n",
    "        decay_rate: Rate at which strength decays\n",
    "        patience: Number of validation checks without improvement before decay\n",
    "        counter: Current patience counter\n",
    "        best_loss: Best validation loss observed\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initial_strength: float = 1.0, decay_rate: float = 0.98, patience: int = 2) -> None:\n",
    "        self.strength = initial_strength\n",
    "        self.decay_rate = decay_rate\n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        self.best_loss = float('inf')\n",
    "\n",
    "    def update(self, validation_loss: float) -> None:\n",
    "        \"\"\"Update augmentation strength based on validation loss\"\"\"\n",
    "        if validation_loss < self.best_loss:\n",
    "            self.best_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                old_strength = self.strength\n",
    "                self.strength *= self.decay_rate\n",
    "                logging.info(f\"Augmentation strength decayed from {old_strength:.3f} to {self.strength:.3f}\")\n",
    "                self.counter = 0"
   ],
   "id": "f862384e427128cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class WarmRestartMonitor:\n",
    "    \"\"\"Monitor and log warm restarts for CosineAnnealingWarmRestarts\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.last_lr = None\n",
    "        self.restart_count = 0\n",
    "        self.step_count = 0\n",
    "        self.warmup_complete = False\n",
    "        self.min_lr_seen = float('inf')\n",
    "\n",
    "    def check_restart(self, current_lr: float) -> bool:\n",
    "        \"\"\"Check if a restart occurred based on learning rate increase\"\"\"\n",
    "        restart_detected = False\n",
    "\n",
    "        # Skip restart detection during warmup\n",
    "        if not self.warmup_complete:\n",
    "            if self.last_lr is not None and current_lr < self.last_lr:\n",
    "                self.warmup_complete = True\n",
    "                logging.info(f\"Warmup completed at step {self.step_count}, starting restart monitoring\")\n",
    "\n",
    "        if self.warmup_complete and self.last_lr is not None:\n",
    "            # Track minimum LR to detect restarts more reliably\n",
    "            self.min_lr_seen = min(self.min_lr_seen, self.last_lr)\n",
    "\n",
    "            # Detect restart: significant LR increase from recent minimum\n",
    "            lr_increase_ratio = current_lr / self.last_lr\n",
    "            min_increase_from_bottom = current_lr / self.min_lr_seen\n",
    "\n",
    "            if (lr_increase_ratio > cfg.LR_RESTART_DETECTION_THRESHOLD or  # Primary threshold for restart detection\n",
    "                (lr_increase_ratio > cfg.LR_RESTART_SECONDARY_THRESHOLD and min_increase_from_bottom > cfg.LR_RESTART_MIN_INCREASE_RATIO)):  # Secondary threshold + far from minimum\n",
    "\n",
    "                self.restart_count += 1\n",
    "                logging.info(f\"ðŸ”„ Warm restart #{self.restart_count} detected at step {self.step_count} \"\n",
    "                            f\"(LR: {self.last_lr:.2e} â†’ {current_lr:.2e}, ratio: {lr_increase_ratio:.1f}x)\")\n",
    "                self.min_lr_seen = float('inf')  # Reset minimum tracking\n",
    "                restart_detected = True\n",
    "\n",
    "        self.last_lr = current_lr\n",
    "        self.step_count += 1\n",
    "        return restart_detected"
   ],
   "id": "693e652987e10588"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data and Preprocessing\n",
    "\n",
    "This section details how the seismic and velocity data are discovered, split, loaded, and augmented for the training process. Efficient and robust data pipelines are critical for deep learning."
   ],
   "id": "ab7e155f1932b601"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def scan_files(root_dir: Path) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Scan directory for input/target file pairs and group them by type\"\"\"\n",
    "    file_pairs = []\n",
    "    for item in sorted(root_dir.iterdir()):\n",
    "        if not item.is_dir():\n",
    "            continue\n",
    "\n",
    "        name = item.name\n",
    "        group = \"Unknown\"\n",
    "        if \"Vel\" in name:\n",
    "            group = \"Vel\"\n",
    "        elif \"Style\" in name:\n",
    "            group = \"Style\"\n",
    "        elif \"Fault\" in name:\n",
    "            group = \"Fault\"\n",
    "\n",
    "        # Match data/model pairs\n",
    "        for data_file in sorted(item.glob(\"data*.npy\")):\n",
    "            match = re.search(r\"data(\\d+)\\.npy\", data_file.name)\n",
    "            if match:\n",
    "                idx = match.group(1)\n",
    "                model_file = item / f\"model{idx}.npy\"\n",
    "                if model_file.exists():\n",
    "                    file_pairs.append({\"input\": data_file, \"target\": model_file, \"group\": group})\n",
    "\n",
    "        # Match seis/vel pairs\n",
    "        for seis_file in sorted(item.glob(\"seis*.npy\")):\n",
    "            vel_file = item / seis_file.name.replace(\"seis\", \"vel\", 1)\n",
    "            if vel_file.exists():\n",
    "                file_pairs.append({\"input\": seis_file, \"target\": vel_file, \"group\": group})\n",
    "\n",
    "    return file_pairs"
   ],
   "id": "57b90e4408f4b2d5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_stratified_split(file_pairs: List[Dict[str, Any]], val_frac: float) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:\n",
    "    \"\"\"Create stratified train/validation split maintaining group proportions\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for pair in file_pairs:\n",
    "        groups[pair[\"group\"]].append(pair)\n",
    "\n",
    "    train_files, val_files = [], []\n",
    "    for group, items in groups.items():\n",
    "        random.shuffle(items)\n",
    "        n_val = max(1, int(len(items) * val_frac))\n",
    "        val_files.extend(items[:n_val])\n",
    "        train_files.extend(items[n_val:])\n",
    "\n",
    "    random.shuffle(train_files)\n",
    "    random.shuffle(val_files)\n",
    "    return train_files, val_files"
   ],
   "id": "3477a6f82025c465"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_class_weights(train_pairs: List[Dict[str, Any]], ddp_manager: DDPManager) -> Optional[Dict[str, float]]:\n",
    "    \"\"\"Calculate class weights for loss balancing\"\"\"\n",
    "    if not cfg.USE_LOSS_WEIGHTING:\n",
    "        return None\n",
    "\n",
    "    logging.info(\"Calculating class weights for loss balancing...\")\n",
    "    group_counts = defaultdict(int)\n",
    "    total_samples = 0\n",
    "\n",
    "    for pair in train_pairs:\n",
    "        group_counts[pair['group']] += 1\n",
    "        total_samples += 1\n",
    "\n",
    "    if total_samples == 0:\n",
    "        return None\n",
    "\n",
    "    num_classes = len(group_counts)\n",
    "    weights = {}\n",
    "\n",
    "    # Inverse frequency weighting\n",
    "    for group, count in group_counts.items():\n",
    "        weights[group] = total_samples / (num_classes * count)\n",
    "\n",
    "    # Normalize weights\n",
    "    max_weight = max(weights.values())\n",
    "    for group in weights:\n",
    "        weights[group] /= max_weight\n",
    "\n",
    "    if ddp_manager.is_main_process():\n",
    "        logging.info(f\"Calculated loss weights: {weights}\")\n",
    "\n",
    "    return weights"
   ],
   "id": "694e8bd2e442014e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def log_dataset_info(train_pairs: List[Dict[str, Any]], val_pairs: List[Dict[str, Any]]) -> None:\n",
    "    \"\"\"Log detailed information about dataset splits\"\"\"\n",
    "    logging.info(\"--- Dataset Analysis ---\")\n",
    "\n",
    "    def analyze_split(name: str, pairs: List[Dict]) -> None:\n",
    "        if not pairs:\n",
    "            logging.info(f\"{name} set is empty.\")\n",
    "            return\n",
    "\n",
    "        group_counts = defaultdict(int)\n",
    "        total_samples = 0\n",
    "\n",
    "        for pair in tqdm(pairs, desc=f\"Scanning {name} files\", leave=False):\n",
    "            try:\n",
    "                with open(pair['input'], 'rb') as f:\n",
    "                    version = np.lib.format.read_magic(f)\n",
    "                    shape, _, _ = np.lib.format._read_array_header(f, version)\n",
    "                    num_samples_in_file = shape[0]\n",
    "\n",
    "                group = pair['group']\n",
    "                group_counts[group] += num_samples_in_file\n",
    "                total_samples += num_samples_in_file\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Could not read shape for {pair['input']}: {e}\")\n",
    "\n",
    "        logging.info(f\"Split: {name} | Total Samples: {total_samples}\")\n",
    "        for group, count in sorted(group_counts.items()):\n",
    "            logging.info(f\"  - Group: {group:<6} | Samples: {count}\")\n",
    "\n",
    "    analyze_split(\"Training\", train_pairs)\n",
    "    analyze_split(\"Validation\", val_pairs)\n",
    "    logging.info(\"------------------------\")"
   ],
   "id": "42789cb61c9dd152"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class FWIDataset(Dataset):\n",
    "    \"\"\"Dataset for loading FWI training samples\"\"\"\n",
    "\n",
    "    def __init__(self, metadata: List[Dict[str, Any]], device: torch.device) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            metadata: List of dicts containing input/target file paths\n",
    "            device: Target device for data loading\n",
    "        \"\"\"\n",
    "        self.metadata_files = metadata\n",
    "        self.device = device\n",
    "        self.flat_index = []\n",
    "\n",
    "        # Build flat index mapping (file_idx, sample_idx)\n",
    "        for file_idx, pair in enumerate(self.metadata_files):\n",
    "            try:\n",
    "                num_samples = np.load(pair[\"input\"], mmap_mode='r').shape[0]\n",
    "                self.flat_index.extend([(file_idx, sample_idx) for sample_idx in range(num_samples)])\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to process file {pair['input']}: {e}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.flat_index)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor, str]:\n",
    "        \"\"\"Load and preprocess a single sample with retry mechanism\"\"\"\n",
    "        max_retries = cfg.MAX_RETRIES\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                file_idx, sample_idx = self.flat_index[idx]\n",
    "                sample_info = self.metadata_files[file_idx]\n",
    "\n",
    "                # Load input and target data\n",
    "                input_data = np.load(sample_info['input'], mmap_mode='r')[sample_idx].copy()\n",
    "                target_data = np.load(sample_info['target'], mmap_mode='r')[sample_idx].copy()\n",
    "                group = sample_info['group']\n",
    "\n",
    "                # Validate data integrity\n",
    "                if np.isnan(input_data).any() or np.isnan(target_data).any():\n",
    "                    raise ValueError(f\"NaN values detected in data for sample {idx}\")\n",
    "\n",
    "                if input_data.size == 0 or target_data.size == 0:\n",
    "                    raise ValueError(f\"Empty data arrays for sample {idx}\")\n",
    "\n",
    "                # Convert to tensors\n",
    "                seismic = torch.from_numpy(input_data).float()\n",
    "                velocity = torch.from_numpy(target_data).float()\n",
    "\n",
    "                # Handle different input formats\n",
    "                if group == 'Fault' and seismic.ndim == 2:\n",
    "                    seismic = seismic.unsqueeze(0).repeat(cfg.NUM_SOURCES, 1, 1)\n",
    "                if velocity.ndim == 2:\n",
    "                    velocity = velocity.unsqueeze(0)\n",
    "\n",
    "                return seismic, velocity, group\n",
    "\n",
    "            except Exception as e:\n",
    "                if attempt < max_retries - 1:\n",
    "                    logging.warning(f\"Attempt {attempt + 1} failed for sample {idx}: {e}. Retrying...\")\n",
    "                    # Try a different sample on retry to avoid persistent corruption\n",
    "                    idx = (idx + 1) % len(self.flat_index)\n",
    "                    continue\n",
    "                else:\n",
    "                    # All retries exhausted - raise error to fail fast\n",
    "                    logging.error(f\"Failed to load sample {idx} after {max_retries} attempts: {e}\")\n",
    "                    raise RuntimeError(f\"Failed to load sample {idx} after {max_retries} attempts\") from e"
   ],
   "id": "a4fcb61e551ab670"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class GPUBatchProcessor:\n",
    "    \"\"\"Handles batch processing and augmentations on GPU\"\"\"\n",
    "\n",
    "    def __init__(self, device: torch.device, aug_scheduler: AdaptiveAugmentation) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            device: Target device for processing\n",
    "            aug_scheduler: Adaptive augmentation controller\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.aug_scheduler = aug_scheduler\n",
    "        self.velocity_min = torch.tensor(cfg.VELOCITY_MIN, device=device)\n",
    "        self.velocity_range = torch.tensor(cfg.VELOCITY_MAX - cfg.VELOCITY_MIN, device=device)\n",
    "\n",
    "    def _elastic_deform(self, image: torch.Tensor, alpha: float, sigma: float) -> torch.Tensor:\n",
    "        \"\"\"Apply elastic deformation to input images\"\"\"\n",
    "        B, _, H, W = image.shape\n",
    "        coords_y, coords_x = torch.meshgrid(\n",
    "            torch.arange(H, device=self.device),\n",
    "            torch.arange(W, device=self.device),\n",
    "            indexing='ij'\n",
    "        )\n",
    "        coords = torch.stack([coords_y, coords_x], dim=0).float()\n",
    "\n",
    "        # Generate random displacement fields\n",
    "        dx = torch.randn(B, H, W, device=self.device) * sigma\n",
    "        dy = torch.randn(B, H, W, device=self.device) * sigma\n",
    "\n",
    "        # Smooth displacement fields\n",
    "        kernel_size = int(aug_params.GAUSSIAN_BLUR_KERNEL_MULTIPLIER * sigma + 1)\n",
    "        if kernel_size % 2 == 0:\n",
    "            kernel_size += 1\n",
    "\n",
    "        dx = TF.gaussian_blur(dx.unsqueeze(1), kernel_size=(kernel_size, kernel_size)).squeeze(1)\n",
    "        dy = TF.gaussian_blur(dy.unsqueeze(1), kernel_size=(kernel_size, kernel_size)).squeeze(1)\n",
    "\n",
    "        # Apply displacement\n",
    "        displaced_coords = coords + alpha * torch.stack([dy, dx], dim=1)\n",
    "        displaced_coords = displaced_coords.permute(0, 2, 3, 1)\n",
    "        norm_coords = 2 * (displaced_coords / torch.tensor([W-1, H-1], device=self.device) - 0.5)\n",
    "\n",
    "        return F.grid_sample(\n",
    "            image, norm_coords,\n",
    "            mode='bilinear',\n",
    "            padding_mode='reflection',\n",
    "            align_corners=False\n",
    "        )\n",
    "\n",
    "    def _augment_velocity(self, velocity: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply velocity-specific augmentations\"\"\"\n",
    "        aug_strength = self.aug_scheduler.strength\n",
    "\n",
    "        # Velocity scaling\n",
    "        if augs.VELOCITY_AUG and torch.rand(1) < aug_params.VEL_AUG_PROB * aug_strength:\n",
    "            scales = 1.0 + (torch.rand(velocity.size(0), 1, 1, 1, device=self.device) * 2 - 1) * aug_params.VEL_AUG_SCALE * aug_strength\n",
    "            velocity = velocity * scales\n",
    "\n",
    "        # Velocity smoothing\n",
    "        if augs.VELOCITY_SMOOTH and torch.rand(1) < aug_params.VEL_SMOOTH_PROB * aug_strength:\n",
    "            kernel_size = random.choice([3, 5])\n",
    "            velocity = F.avg_pool2d(\n",
    "                velocity,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=1,\n",
    "                padding=kernel_size // 2\n",
    "            )\n",
    "\n",
    "        return torch.clamp(velocity, cfg.VELOCITY_MIN, cfg.VELOCITY_MAX)\n",
    "\n",
    "    def _simulate_faults(self, velocity: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Simulate geological faults in velocity models\"\"\"\n",
    "        batch_size, _, h, w = velocity.shape\n",
    "        x, y = torch.arange(w, device=self.device), torch.arange(h, device=self.device)\n",
    "        xx, yy = torch.meshgrid(x, y, indexing='xy')\n",
    "\n",
    "        # Generate random fault lines\n",
    "        angles = torch.rand(batch_size, device=self.device) * math.pi\n",
    "        offsets = (torch.rand(batch_size, device=self.device) * 2 - 1) * math.sqrt(h**2+w**2) * 0.2\n",
    "        mask = (xx * torch.cos(angles).view(-1, 1, 1) + yy * torch.sin(angles).view(-1, 1, 1)) > offsets.view(-1, 1, 1)\n",
    "\n",
    "        # Apply displacement along faults\n",
    "        displacement = (torch.rand_like(velocity) * 2 - 1) * self.velocity_range * aug_params.FAULT_NOISE_STRENGTH\n",
    "        velocity[mask.unsqueeze(1)] += displacement[mask.unsqueeze(1)]\n",
    "\n",
    "        return torch.clamp(velocity, cfg.VELOCITY_MIN, cfg.VELOCITY_MAX)\n",
    "\n",
    "    def process_batch(self, seismic: torch.Tensor, velocity: Optional[torch.Tensor] = None,\n",
    "                     groups: Optional[List[str]] = None, is_train: bool = False) -> Tuple:\n",
    "        \"\"\"\n",
    "        Process a batch of data including normalization and augmentations.\n",
    "\n",
    "        Args:\n",
    "            seismic: Input seismic data\n",
    "            velocity: Target velocity data (optional)\n",
    "            groups: Data group labels (optional)\n",
    "            is_train: Whether to apply training augmentations\n",
    "\n",
    "        Returns:\n",
    "            Tuple of (processed_seismic, normalized_velocity, denormalized_velocity)\n",
    "        \"\"\"\n",
    "        # Transfer to device\n",
    "        seismic = seismic.to(self.device, non_blocking=True)\n",
    "        original_velocity = velocity\n",
    "        if velocity is not None:\n",
    "            velocity = velocity.to(self.device, non_blocking=True)\n",
    "\n",
    "        # Apply augmentations during training\n",
    "        aug_strength = self.aug_scheduler.strength if is_train else 0.0\n",
    "\n",
    "        if is_train and velocity is not None:\n",
    "            # Elastic deformation\n",
    "            if augs.ELASTIC_DEFORM and torch.rand(1) < aug_params.ELASTIC_DEFORM_PROB * aug_strength:\n",
    "                velocity = self._elastic_deform(\n",
    "                    velocity,\n",
    "                    alpha=random.uniform(*cfg.ELASTIC_ALPHA_RANGE),\n",
    "                    sigma=random.uniform(*cfg.ELASTIC_SIGMA_RANGE)\n",
    "                )\n",
    "\n",
    "            # Fault simulation\n",
    "            if augs.FAULT_SIMULATION and torch.rand(1) < aug_params.FAULT_NOISE_PROB * aug_strength:\n",
    "                velocity = self._simulate_faults(velocity)\n",
    "\n",
    "            # Amplitude jitter\n",
    "            if augs.AMP_JITTER and torch.rand(1) < aug_params.AMP_JITTER_PROB * aug_strength:\n",
    "                seismic *= (1.0 + (torch.rand(seismic.size(0), 1, 1, 1, device=self.device) * 2 - 1) * aug_params.AMP_JITTER_SCALE)\n",
    "\n",
    "            # Receiver dropout\n",
    "            if augs.RECEIVER_DROP and torch.rand(1) < aug_params.RECEIVER_DROP_PROB * aug_strength:\n",
    "                num_drops = torch.randint(1, aug_params.MAX_RECEIVER_DROPS + 1, (1,)).item()\n",
    "                if seismic.dim() == 4 and seismic.size(1) == cfg.NUM_SOURCES:\n",
    "                    perm = torch.rand(seismic.size(0), cfg.NUM_SOURCES, device=self.device).argsort(dim=1)\n",
    "                    seismic[torch.arange(seismic.size(0), device=self.device).unsqueeze(1), perm[:, :num_drops]] = 0.0\n",
    "\n",
    "            # Gaussian noise\n",
    "            if augs.GAUSSIAN_NOISE:\n",
    "                seismic += torch.randn_like(seismic) * aug_params.NOISE_STD * aug_strength\n",
    "\n",
    "        # Normalize seismic data\n",
    "        mean = seismic.mean(dim=(-1, -2), keepdim=True)\n",
    "        std = torch.clamp(seismic.std(dim=(-1, -2), keepdim=True), min=cfg.MIN_STD_CLAMP)\n",
    "        seismic = (seismic - mean) / std\n",
    "\n",
    "        # Handle NaN values\n",
    "        if torch.isnan(seismic).any():\n",
    "            logging.warning(\"NaN values detected in seismic data after normalization. Replacing with zeros.\")\n",
    "            seismic = torch.nan_to_num(seismic)\n",
    "\n",
    "        # Normalize velocity if provided\n",
    "        if velocity is not None:\n",
    "            norm_velocity = (velocity - self.velocity_min) / self.velocity_range\n",
    "            return seismic, norm_velocity, original_velocity.to(self.device) if original_velocity is not None else None\n",
    "\n",
    "        return seismic, None, None\n",
    "\n",
    "    def denormalize(self, norm_vel: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Convert normalized velocity back to original scale\"\"\"\n",
    "        return norm_vel * self.velocity_range + self.velocity_min"
   ],
   "id": "cf3508928ef1ec66"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Model Architecture\n",
    "\n",
    "This extensive section defines the neural network architecture, along with crucial helper classes and functions for effective model training, evaluation, and deployment."
   ],
   "id": "5e280a7f96c1c7a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SCSEBlock(nn.Module):\n",
    "    \"\"\"Squeeze-and-Excitation block with spatial attention\"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, reduction: int = cfg.SCSE_REDUCTION) -> None:\n",
    "        super().__init__()\n",
    "        # Channel attention\n",
    "        self.cSE = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(channels, channels//reduction, 1),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(channels//reduction, channels, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # Spatial attention\n",
    "        self.sSE = nn.Sequential(\n",
    "            nn.Conv2d(channels, 1, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.cSE(x) + x * self.sSE(x)"
   ],
   "id": "610fa7f1712a17d3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LearnedUpsample(nn.Module):\n",
    "    \"\"\"Learned upsampling using PixelShuffle for smooth, artifact-free upsampling\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int, scale_factor: int = 2) -> None:\n",
    "        super().__init__()\n",
    "        self.scale_factor = scale_factor\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels * (scale_factor ** 2),\n",
    "            kernel_size=3,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.pixel_shuffle = nn.PixelShuffle(scale_factor)\n",
    "        self.norm = nn.GroupNorm(cfg.GROUPNORM_GROUPS, out_channels)\n",
    "        self.activation = nn.GELU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.norm(x)\n",
    "        return self.activation(x)"
   ],
   "id": "d8ecd0183adbbad2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"Residual block for decoder with improved skip connections\"\"\"\n",
    "\n",
    "    def __init__(self, channels: int, dropout: float = 0.1) -> None:\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
    "        self.norm1 = nn.GroupNorm(cfg.GROUPNORM_GROUPS, channels)\n",
    "        self.conv2 = nn.Conv2d(channels, channels, 3, padding=1, bias=False)\n",
    "        self.norm2 = nn.GroupNorm(cfg.GROUPNORM_GROUPS, channels)\n",
    "        self.activation = nn.GELU()\n",
    "        self.dropout = nn.Dropout2d(dropout)\n",
    "        self.scse = SCSEBlock(channels)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        residual = x\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        # Add residual connection\n",
    "        x = x + residual\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Apply attention\n",
    "        x = self.scse(x)\n",
    "\n",
    "        return x"
   ],
   "id": "b3829500cd87fd6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EnhancedUNetDecoderBlock(nn.Module):\n",
    "    \"\"\"Enhanced decoder block with learned upsampling and improved residual connections\"\"\"\n",
    "\n",
    "    def __init__(self, in_ch: int, skip_ch: int, out_ch: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Learned upsampling instead of simple interpolation\n",
    "        self.learned_upsample = LearnedUpsample(in_ch, in_ch)\n",
    "\n",
    "        # Channel reduction for concatenated features\n",
    "        concat_ch = in_ch + skip_ch\n",
    "        self.channel_reduce = nn.Conv2d(concat_ch, out_ch, 1, bias=False)\n",
    "        self.reduce_norm = nn.GroupNorm(cfg.GROUPNORM_GROUPS, out_ch)\n",
    "\n",
    "        # Residual processing blocks\n",
    "        self.res_block1 = ResidualBlock(out_ch, cfg.DECODER_DROPOUT)\n",
    "        self.res_block2 = ResidualBlock(out_ch, cfg.DECODER_DROPOUT)\n",
    "\n",
    "        # Skip connection for the entire block\n",
    "        self.skip_conv = nn.Conv2d(concat_ch, out_ch, 1, bias=False) if concat_ch != out_ch else nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor, skip: torch.Tensor) -> torch.Tensor:\n",
    "        # Learned upsampling\n",
    "        x_up = self.learned_upsample(x)\n",
    "\n",
    "        # Concatenate with skip connection\n",
    "        x_concat = torch.cat([x_up, skip], dim=1)\n",
    "\n",
    "        # Store for skip connection\n",
    "        skip_input = x_concat\n",
    "\n",
    "        # Channel reduction\n",
    "        x = self.channel_reduce(x_concat)\n",
    "        x = self.reduce_norm(x)\n",
    "        x = F.gelu(x)\n",
    "\n",
    "        # Residual processing\n",
    "        x = self.res_block1(x)\n",
    "        x = self.res_block2(x)\n",
    "\n",
    "        # Block-level skip connection\n",
    "        if not isinstance(self.skip_conv, nn.Identity):\n",
    "            skip_processed = self.skip_conv(skip_input)\n",
    "            x = x + skip_processed\n",
    "\n",
    "        return x"
   ],
   "id": "ad50a5a3c29d42b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MultiSourceUNetSwin(nn.Module):\n",
    "    \"\"\"Main model combining Swin Transformer backbone with UNet-like decoder\"\"\"\n",
    "\n",
    "    def __init__(self, ddp_manager: DDPManager) -> None:\n",
    "        super().__init__()\n",
    "        # Initial stem convolution\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(1, cfg.STEM_CHANNELS, 3, padding=1, bias=False),\n",
    "            nn.GroupNorm(cfg.GROUPNORM_GROUPS, cfg.STEM_CHANNELS),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(cfg.STEM_CHANNELS, cfg.STEM_CHANNELS, 3, padding=1, bias=False),\n",
    "            nn.GroupNorm(cfg.GROUPNORM_GROUPS, cfg.STEM_CHANNELS),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(cfg.STEM_CHANNELS, cfg.RGB_CHANNELS, 1, bias=False)\n",
    "        )\n",
    "\n",
    "        # Load backbone (Swin Transformer V2) with warning suppression\n",
    "        if ddp_manager.is_ddp:\n",
    "            # Ensure all processes load the same pretrained weights\n",
    "            if ddp_manager.is_main_process():\n",
    "                self.backbone = timm.create_model(\n",
    "                    cfg.MODEL_NAME,\n",
    "                    pretrained=cfg.PRETRAINED,\n",
    "                    in_chans=cfg.RGB_CHANNELS,\n",
    "                    features_only=True\n",
    "                )\n",
    "            safe_barrier(ddp_manager)\n",
    "            if not ddp_manager.is_main_process():\n",
    "                self.backbone = timm.create_model(\n",
    "                    cfg.MODEL_NAME,\n",
    "                    pretrained=cfg.PRETRAINED,\n",
    "                    in_chans=cfg.RGB_CHANNELS,\n",
    "                    features_only=True\n",
    "                )\n",
    "        else:\n",
    "            self.backbone = timm.create_model(\n",
    "                cfg.MODEL_NAME,\n",
    "                pretrained=cfg.PRETRAINED,\n",
    "                in_chans=cfg.RGB_CHANNELS,\n",
    "                features_only=True\n",
    "            )\n",
    "\n",
    "        # Enable gradient checkpointing if available\n",
    "        if hasattr(self.backbone, 'set_grad_checkpointing'):\n",
    "            self.backbone.set_grad_checkpointing(True)\n",
    "            if ddp_manager.is_main_process():\n",
    "                logging.info(\"Gradient checkpointing enabled for backbone.\")\n",
    "\n",
    "        # Build enhanced decoder with learned upsampling and residual blocks\n",
    "        enc_channels = self.backbone.feature_info.channels()\n",
    "        dec_channels = cfg.DECODER_CHANNELS\n",
    "\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(f\"Building enhanced decoder with channels: {dec_channels}\")\n",
    "            logging.info(f\"Encoder channels: {enc_channels}\")\n",
    "\n",
    "        decoder_layers = []\n",
    "        in_ch = enc_channels[-1]\n",
    "\n",
    "        for i in range(len(dec_channels)):\n",
    "            skip_ch = enc_channels[-(i+2)]\n",
    "            out_ch = dec_channels[i]\n",
    "            decoder_layers.append(EnhancedUNetDecoderBlock(in_ch, skip_ch, out_ch))\n",
    "            if ddp_manager.is_main_process():\n",
    "                logging.info(f\"Decoder layer {i}: {in_ch} + {skip_ch} -> {out_ch}\")\n",
    "            in_ch = out_ch\n",
    "\n",
    "        self.decoders = nn.ModuleList(decoder_layers)\n",
    "\n",
    "        # Enhanced final processing with residual refinement\n",
    "        self.final_refine = nn.Sequential(\n",
    "            ResidualBlock(dec_channels[-1], cfg.DECODER_DROPOUT * 0.5),  # Less dropout for final layer\n",
    "            nn.Conv2d(dec_channels[-1], dec_channels[-1] // 2, 3, padding=1, bias=False),\n",
    "            nn.GroupNorm(cfg.GROUPNORM_GROUPS, dec_channels[-1] // 2),\n",
    "            nn.GELU(),\n",
    "            nn.Conv2d(dec_channels[-1] // 2, cfg.OUTPUT_CHANNELS, 1)\n",
    "        )\n",
    "\n",
    "        # Log decoder enhancement info\n",
    "        if ddp_manager.is_main_process():\n",
    "            decoder_params = sum(p.numel() for p in self.decoders.parameters()) + sum(p.numel() for p in self.final_refine.parameters())\n",
    "            total_params = sum(p.numel() for p in self.parameters())\n",
    "            logging.info(f\"Enhanced decoder parameters: {decoder_params:,} ({decoder_params/total_params*100:.1f}% of total)\")\n",
    "            logging.info(\"Decoder enhancements: Learned upsampling + Residual blocks + Enhanced final processing\")\n",
    "\n",
    "    def encode(self, x: torch.Tensor) -> List[torch.Tensor]:\n",
    "        \"\"\"Encode input through backbone and return feature maps\"\"\"\n",
    "        x = self.stem(x)\n",
    "        x = F.interpolate(x, size=(cfg.BACKBONE_INPUT_SIZE, cfg.BACKBONE_INPUT_SIZE), mode='bilinear', align_corners=False)\n",
    "        features = self.backbone(x)\n",
    "\n",
    "        # Handle potential channel-last format\n",
    "        if features and features[0].ndim == 4 and features[0].shape[-1] == self.backbone.feature_info[0]['num_chs']:\n",
    "            features = [o.permute(0, 3, 1, 2) for o in features]\n",
    "\n",
    "        return features\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass with multi-source aggregation\"\"\"\n",
    "        B, S, H, W = x.shape\n",
    "\n",
    "        # Process each source independently\n",
    "        x_batched = x.reshape(B * S, 1, H, W)\n",
    "        all_skips = self.encode(x_batched)\n",
    "\n",
    "        # Average features across sources\n",
    "        avg_skips = []\n",
    "        for skip_tensor in all_skips:\n",
    "            _, C, H_feat, W_feat = skip_tensor.shape\n",
    "            reshaped_skip = skip_tensor.reshape(B, S, C, H_feat, W_feat)\n",
    "            avg_skip = reshaped_skip.mean(dim=1)\n",
    "            avg_skips.append(avg_skip)\n",
    "\n",
    "        # Decode averaged features\n",
    "        dec = avg_skips[-1]\n",
    "        for i in range(len(self.decoders)):\n",
    "            dec = self.decoders[i](dec, avg_skips[-(i+2)])\n",
    "\n",
    "        # Final output with learned upsampling to target size\n",
    "        if dec.shape[-2:] != (cfg.OUTPUT_HEIGHT, cfg.OUTPUT_WIDTH):\n",
    "            dec = F.interpolate(dec, size=(cfg.OUTPUT_HEIGHT, cfg.OUTPUT_WIDTH), mode='bilinear', align_corners=False)\n",
    "\n",
    "        return self.final_refine(dec)"
   ],
   "id": "719a8f8a2b32c984"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Utilities",
   "id": "7d370b8f85695d46"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ModelEMA:\n",
    "    \"\"\"Exponential Moving Average of model weights\"\"\"\n",
    "\n",
    "    def __init__(self, model: nn.Module, decay: float = cfg.EMA_DECAY) -> None:\n",
    "        self.ema_model = copy.deepcopy(model).eval()\n",
    "        self.decay = decay\n",
    "        for p in self.ema_model.parameters():\n",
    "            p.requires_grad_(False)\n",
    "\n",
    "    def update(self, model: nn.Module) -> None:\n",
    "        \"\"\"Update EMA weights\"\"\"\n",
    "        with torch.no_grad():\n",
    "            for ema_p, p in zip(self.ema_model.parameters(), model.parameters()):\n",
    "                ema_p.copy_(self.decay * ema_p + (1.0 - self.decay) * p)\n",
    "\n",
    "    def state_dict(self) -> Dict[str, torch.Tensor]:\n",
    "        return self.ema_model.state_dict()\n",
    "\n",
    "    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]) -> None:\n",
    "        self.ema_model.load_state_dict(state_dict)\n",
    "\n",
    "    def to(self, device: torch.device) -> 'ModelEMA':\n",
    "        self.ema_model.to(device)\n",
    "        return self"
   ],
   "id": "d7dbad3ec0d88d75"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping based on validation metric\"\"\"\n",
    "\n",
    "    def __init__(self, patience: int = cfg.PATIENCE, verbose: bool = True) -> None:\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_metric: float, model_to_save: nn.Module, path: Path) -> None:\n",
    "        \"\"\"\n",
    "        Check if early stopping criteria met\n",
    "\n",
    "        Args:\n",
    "            val_metric: Current validation metric\n",
    "            model_to_save: Model to save if metric improves\n",
    "            path: Path to save best model\n",
    "        \"\"\"\n",
    "        if self.best_score is None or val_metric < self.best_score:\n",
    "            self.best_score = val_metric\n",
    "            if self.verbose:\n",
    "                logging.info(f\"Metric improved to {self.best_score:.4f}. Saving best EMA model.\")\n",
    "            torch.save(model_to_save.state_dict(), path)\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                logging.info(f\"EarlyStopping counter: {self.counter}/{self.patience}\")\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True"
   ],
   "id": "cfd62582eafcb1a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MetricsLogger:\n",
    "    \"\"\"Handles logging metrics to TensorBoard\"\"\"\n",
    "\n",
    "    def __init__(self, log_dir: Path) -> None:\n",
    "        self.writer = SummaryWriter(log_dir)\n",
    "\n",
    "    def log(self, metrics: Dict[str, float], epoch: int) -> None:\n",
    "        \"\"\"Log metrics for current epoch\"\"\"\n",
    "        for key, value in metrics.items():\n",
    "            if not math.isnan(value):\n",
    "                self.writer.add_scalar(key, value, epoch)\n",
    "\n",
    "    def close(self) -> None:\n",
    "        self.writer.close()"
   ],
   "id": "2ad950259641668a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def save_checkpoint(\n",
    "    epoch: int,\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "    ema: ModelEMA,\n",
    "    path: Path,\n",
    "    history: Dict[str, List[float]],\n",
    "    ddp_manager: DDPManager\n",
    ") -> None:\n",
    "    # Ensure only the main process saves the checkpoint in DDP\n",
    "    if hasattr(ddp_manager, 'is_main_process') and not ddp_manager.is_main_process():\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Saving checkpoint to {path} at epoch {epoch + 1}\")\n",
    "\n",
    "        # Ensure the directory exists\n",
    "        path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Get the unwrapped model state dict\n",
    "        model_state_dict = model.module.state_dict() if hasattr(model, 'module') else model.state_dict()\n",
    "\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model_state_dict,\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict': scheduler.state_dict(),\n",
    "            'ema_model_state_dict': ema.ema_model.state_dict() if ema else None,\n",
    "            'history': history,\n",
    "            # Save RNG states for reproducibility\n",
    "            'rng_state_torch': torch.get_rng_state(),\n",
    "            'rng_state_cuda': torch.cuda.get_rng_state() if torch.cuda.is_available() else None,\n",
    "            'rng_state_numpy': np.random.get_state(),\n",
    "            'rng_state_random': random.getstate(),\n",
    "        }\n",
    "\n",
    "        # Save to temporary file first, then rename for atomic operation\n",
    "        temp_path = path.with_suffix('.tmp')\n",
    "        torch.save(state, temp_path)\n",
    "        temp_path.rename(path)\n",
    "\n",
    "        logging.info(f\"Successfully saved checkpoint to {path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to save checkpoint to {path}: {e}\")\n",
    "        # Clean up temporary file if it exists\n",
    "        temp_path = path.with_suffix('.tmp')\n",
    "        if temp_path.exists():\n",
    "            temp_path.unlink()\n",
    "        raise"
   ],
   "id": "edaf59ac43edba87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_checkpoint(\n",
    "    checkpoint_path: Path,\n",
    "    model: torch.nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "    ema: ModelEMA,\n",
    "    ddp_manager: DDPManager\n",
    ") -> Tuple[int, Dict[str, List[float]]]:\n",
    "\n",
    "    if not checkpoint_path.exists():\n",
    "        logging.warning(f\"Checkpoint not found at {checkpoint_path}\")\n",
    "        return 0, defaultdict(list) # Return start_epoch 0 and empty history\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"Loading checkpoint from {checkpoint_path}\")\n",
    "        # Use device-agnostic map_location\n",
    "        map_location = ddp_manager.device if ddp_manager.is_ddp else 'cpu'\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=map_location)\n",
    "\n",
    "        # Load model states (ensure model is unwrapped if DDP)\n",
    "        model_to_load = model.module if hasattr(model, 'module') else model\n",
    "        model_to_load.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "        # Load optimizer and scheduler states\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "        # Load EMA model if available\n",
    "        if ema and 'ema_model_state_dict' in checkpoint and checkpoint['ema_model_state_dict'] is not None:\n",
    "            ema.ema_model.load_state_dict(checkpoint['ema_model_state_dict'])\n",
    "\n",
    "        # Restore history\n",
    "        loaded_history = checkpoint.get('history', defaultdict(list))\n",
    "\n",
    "        # Restore RNG states with rank-specific seeding for DDP\n",
    "        if 'rng_state_torch' in checkpoint:\n",
    "            torch.set_rng_state(checkpoint['rng_state_torch'])\n",
    "        if 'rng_state_cuda' in checkpoint and torch.cuda.is_available():\n",
    "            torch.cuda.set_rng_state(checkpoint['rng_state_cuda'])\n",
    "        if 'rng_state_numpy' in checkpoint:\n",
    "            np.random.set_state(checkpoint['rng_state_numpy'])\n",
    "        if 'rng_state_random' in checkpoint:\n",
    "            random.setstate(checkpoint['rng_state_random'])\n",
    "\n",
    "        # Re-seed with rank offset to maintain different seeds across processes\n",
    "        if ddp_manager.is_ddp:\n",
    "            set_seed(cfg.RANDOM_SEED, ddp_manager.rank)\n",
    "\n",
    "        start_epoch = checkpoint['epoch'] + 1\n",
    "\n",
    "        logging.info(f\"Successfully loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "\n",
    "        # Sync all processes before continuing\n",
    "        if ddp_manager.is_ddp:\n",
    "            safe_barrier(ddp_manager)\n",
    "\n",
    "        return start_epoch, loaded_history\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to load checkpoint from {checkpoint_path}: {e}\")\n",
    "        if ddp_manager.is_ddp:\n",
    "            # Ensure all processes fail together\n",
    "            safe_barrier(ddp_manager)\n",
    "        raise"
   ],
   "id": "4fe84801e46bdd19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def get_scheduler(optimizer: torch.optim.Optimizer, train_loader: DataLoader):\n",
    "    \"\"\"Create learning rate scheduler with warmup and optional warm restarts\"\"\"\n",
    "    warmup_steps = cfg.WARMUP_EPOCHS * len(train_loader) // cfg.ACCUMULATION_STEPS\n",
    "    total_steps = cfg.NUM_EPOCHS * len(train_loader) // cfg.ACCUMULATION_STEPS\n",
    "\n",
    "    if cfg.USE_WARM_RESTARTS:\n",
    "        # For warm restarts, we need to account for the warmup period\n",
    "        # The restart periods should start AFTER warmup\n",
    "        remaining_steps = total_steps - warmup_steps\n",
    "        t_0_steps = cfg.T_0 * len(train_loader) // cfg.ACCUMULATION_STEPS\n",
    "\n",
    "        # Ensure T_0 doesn't exceed remaining training steps\n",
    "        if t_0_steps > remaining_steps:\n",
    "            t_0_steps = max(remaining_steps // 3, 1)  # At least 3 restarts or minimum 1 step\n",
    "            logging.warning(f\"T_0 too large for remaining steps. Adjusted to {t_0_steps} steps\")\n",
    "\n",
    "        warmup = LinearLR(\n",
    "            optimizer,\n",
    "            start_factor=cfg.WARMUP_LR_START_FACTOR,\n",
    "            end_factor=1.0,\n",
    "            total_iters=warmup_steps\n",
    "        )\n",
    "\n",
    "        main_scheduler = CosineAnnealingWarmRestarts(\n",
    "            optimizer,\n",
    "            T_0=t_0_steps,\n",
    "            T_mult=cfg.T_MULT,\n",
    "            eta_min=cfg.ETA_MIN_RESTART\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Using CosineAnnealingWarmRestarts with T_0={t_0_steps} steps ({cfg.T_0} epochs), \"\n",
    "                    f\"T_mult={cfg.T_MULT}, starting after {warmup_steps} warmup steps\")\n",
    "\n",
    "        return SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[warmup, main_scheduler],\n",
    "            milestones=[warmup_steps]\n",
    "        )\n",
    "    else:\n",
    "        warmup = LinearLR(\n",
    "            optimizer,\n",
    "            start_factor=cfg.WARMUP_LR_START_FACTOR,\n",
    "            end_factor=1.0,\n",
    "            total_iters=warmup_steps\n",
    "        )\n",
    "\n",
    "        main_scheduler = CosineAnnealingLR(\n",
    "            optimizer,\n",
    "            T_max=total_steps - warmup_steps,\n",
    "            eta_min=cfg.LR_MIN\n",
    "        )\n",
    "\n",
    "        logging.info(f\"Using CosineAnnealingLR with T_max={total_steps - warmup_steps} steps\")\n",
    "\n",
    "        return SequentialLR(\n",
    "            optimizer,\n",
    "            schedulers=[warmup, main_scheduler],\n",
    "            milestones=[warmup_steps]\n",
    "        )"
   ],
   "id": "5cea447c833b16fc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rescale_to_unit_range(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Rescale tensor to [0, 1] range for SSIM calculation\"\"\"\n",
    "    min_v = x.amin(dim=(-2, -1), keepdim=True)\n",
    "    max_v = x.amax(dim=(-2, -1), keepdim=True)\n",
    "    return (x - min_v) / (max_v - min_v + 1e-8)"
   ],
   "id": "82ea81bc363dd6e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_metrics(history: Dict[str, List[float]], output_dir: Path) -> None:\n",
    "    \"\"\"\n",
    "    Plot and save training metrics.\n",
    "\n",
    "    Args:\n",
    "        history: Dictionary containing metric history\n",
    "        output_dir: Directory to save plot image\n",
    "    \"\"\"\n",
    "    logging.info(\"Plotting training history...\")\n",
    "    num_epochs = len(history['train_loss'])\n",
    "\n",
    "    if num_epochs == 0:\n",
    "        logging.warning(\"History is empty, skipping plotting.\")\n",
    "        return\n",
    "\n",
    "    epochs = range(1, num_epochs + 1)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(18, 10))\n",
    "    fig.suptitle(f'Performance Metrics: {cfg.EXPERIMENT_NAME}', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Plot 1: Normalized Training Loss and Denormalized MAE (Train and Val)\n",
    "    ax_loss = axes[0, 0]\n",
    "    p1, = ax_loss.plot(epochs, history[\"train_loss\"], \".-\", label=\"Train Loss (Normalized)\", color=\"blue\")\n",
    "    ax_loss.set_ylabel(\"Normalized Loss\", color=\"blue\")\n",
    "    ax_loss.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "    ax_loss.set_xlabel(\"Epoch\")\n",
    "    ax_loss.grid(True, ls=\"--\")\n",
    "\n",
    "    ax_mae = ax_loss.twinx()\n",
    "    p2, = ax_mae.plot(epochs, history[\"train_denorm_mae\"], \".-\", label=\"Train MAE (Denormalized)\", color=\"orange\")\n",
    "    p3, = ax_mae.plot(epochs, history[\"val_avg_mae\"], \".-\", label=\"Val MAE (Denormalized, EMA)\", color=\"green\")\n",
    "    ax_mae.set_ylabel(\"MAE (m/s)\", color=\"orange\")\n",
    "    ax_mae.tick_params(axis=\"y\", labelcolor=\"orange\")\n",
    "    ax_mae.grid(False)  # Avoid grid overlap\n",
    "\n",
    "    ax_loss.set_title(\"Normalized Loss & Denormalized MAE\")\n",
    "    ax_loss.legend(handles=[p1, p2, p3], loc='upper right')\n",
    "\n",
    "\n",
    "    # Plot 2: Validation MAE by data group\n",
    "    for group in [\"Vel\", \"Style\", \"Fault\"]:\n",
    "        if f\"val_{group}_mae\" in history and history[f\"val_{group}_mae\"]:\n",
    "            axes[0, 1].plot(epochs, history[f\"val_{group}_mae\"], '.-', label=f\"{group} MAE\")\n",
    "    axes[0, 1].set_title('Validation MAE by Group (EMA)')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('MAE')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, ls='--')\n",
    "\n",
    "    # Plot 3: Validation SSIM by data group\n",
    "    for group in [\"Vel\", \"Style\", \"Fault\"]:\n",
    "        if f\"val_{group}_ssim\" in history and history[f\"val_{group}_ssim\"]:\n",
    "            axes[1, 0].plot(epochs, history[f\"val_{group}_ssim\"], '.-', label=f\"{group} SSIM\")\n",
    "    axes[1, 0].set_title('Validation SSIM by Group (EMA)')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('SSIM')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, ls='--')\n",
    "\n",
    "    # Plot 4: Learning Rate and Gradient Norm\n",
    "    ax_lr = axes[1, 1]\n",
    "    p1, = ax_lr.plot(epochs, history['lr'], '.-', label='LR', color='purple')\n",
    "    ax_lr.set_ylabel('Learning Rate')\n",
    "    ax_lr.set_yscale('log')\n",
    "\n",
    "    ax_gn = ax_lr.twinx()\n",
    "    p2, = ax_gn.plot(epochs, history['grad_norm'], '.-', label='Grad Norm', color='teal', alpha=0.6)\n",
    "    ax_gn.set_ylabel('Gradient Norm')\n",
    "\n",
    "    ax_lr.set_title('Learning Rate & Gradient Norm')\n",
    "    ax_lr.set_xlabel('Epoch')\n",
    "    ax_lr.legend(handles=[p1, p2])\n",
    "    ax_lr.grid(True, ls='--')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(output_dir / f\"{cfg.EXPERIMENT_NAME}_metrics.png\")\n",
    "    plt.close()"
   ],
   "id": "912398d06da965b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_predictions(model: nn.Module, loader: DataLoader,\n",
    "                         batch_processor: GPUBatchProcessor, output_dir: Path):\n",
    "    \"\"\"Visualize model predictions on validation samples\"\"\"\n",
    "    logging.info(\"Plotting validation predictions...\")\n",
    "    model.eval()\n",
    "\n",
    "    # Step 1: Pre-select random samples to visualize (with error handling)\n",
    "    grouped_indices = defaultdict(list)\n",
    "    dataset_size = len(loader.dataset)\n",
    "    max_samples_to_check = min(1000, dataset_size)  # Limit to avoid long iteration\n",
    "\n",
    "    # Randomly sample indices to check instead of iterating through all\n",
    "    indices_to_check = random.sample(range(dataset_size), max_samples_to_check)\n",
    "\n",
    "    for i in indices_to_check:\n",
    "        try:\n",
    "            _, _, group = loader.dataset[i]\n",
    "            grouped_indices[group].append(i)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to access sample {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    samples_to_plot_indices = []\n",
    "    for group in [\"Vel\", \"Style\", \"Fault\"]:\n",
    "        if len(grouped_indices[group]) > 0:\n",
    "            indices = random.sample(grouped_indices[group], min(2, len(grouped_indices[group])))\n",
    "            samples_to_plot_indices.extend(indices)\n",
    "\n",
    "    if not samples_to_plot_indices:\n",
    "        logging.warning(\"No samples found for visualization. Using first available samples from loader.\")\n",
    "        # Fallback: try to get samples directly from the loader\n",
    "        try:\n",
    "            for batch_idx, (seismic, velocity, groups) in enumerate(loader):\n",
    "                if batch_idx == 0:  # Just use first batch\n",
    "                    samples_to_plot_indices = list(range(min(6, len(groups))))\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get samples from loader: {e}\")\n",
    "            return\n",
    "\n",
    "    # Step 2: Get samples for visualization\n",
    "    all_preds, all_targets, all_groups = [], [], []\n",
    "\n",
    "    # Try to use subset if we have valid indices\n",
    "    if samples_to_plot_indices and all(isinstance(idx, int) and 0 <= idx < len(loader.dataset) for idx in samples_to_plot_indices):\n",
    "        try:\n",
    "            vis_dataset = Subset(loader.dataset, samples_to_plot_indices)\n",
    "            vis_loader = DataLoader(vis_dataset, batch_size=len(samples_to_plot_indices))\n",
    "\n",
    "            # Step 3: Run inference on subset\n",
    "            with torch.no_grad():\n",
    "                for seismic, velocity, groups in vis_loader:\n",
    "                    _, _, denorm_vel = batch_processor.process_batch(seismic, velocity, groups, is_train=False)\n",
    "                    norm_seismic, _, _ = batch_processor.process_batch(seismic, is_train=False)\n",
    "\n",
    "                    with torch.cuda.amp.autocast(enabled=cfg.USE_AMP):\n",
    "                        preds_norm = model(norm_seismic)\n",
    "\n",
    "                    denorm_preds = batch_processor.denormalize(preds_norm).cpu()\n",
    "                    all_preds.append(denorm_preds)\n",
    "                    all_targets.append(denorm_vel.cpu())\n",
    "                    all_groups.extend(groups)\n",
    "\n",
    "            all_preds = torch.cat(all_preds)\n",
    "            all_targets = torch.cat(all_targets)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to create subset visualization: {e}. Using first batch from loader.\")\n",
    "            all_preds, all_targets, all_groups = [], [], []\n",
    "\n",
    "    # Fallback: use first batch from original loader\n",
    "    if len(all_preds) == 0:\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                for seismic, velocity, groups in loader:\n",
    "                    # Only take first few samples\n",
    "                    max_vis_samples = min(6, len(groups))\n",
    "                    seismic = seismic[:max_vis_samples]\n",
    "                    velocity = velocity[:max_vis_samples]\n",
    "                    groups = groups[:max_vis_samples]\n",
    "\n",
    "                    _, _, denorm_vel = batch_processor.process_batch(seismic, velocity, groups, is_train=False)\n",
    "                    norm_seismic, _, _ = batch_processor.process_batch(seismic, is_train=False)\n",
    "\n",
    "                    with torch.cuda.amp.autocast(enabled=cfg.USE_AMP):\n",
    "                        preds_norm = model(norm_seismic)\n",
    "\n",
    "                    denorm_preds = batch_processor.denormalize(preds_norm).cpu()\n",
    "                    all_preds.append(denorm_preds)\n",
    "                    all_targets.append(denorm_vel.cpu())\n",
    "                    all_groups.extend(groups)\n",
    "                    break  # Only use first batch\n",
    "\n",
    "            if len(all_preds) > 0:\n",
    "                all_preds = torch.cat(all_preds)\n",
    "                all_targets = torch.cat(all_targets)\n",
    "            else:\n",
    "                logging.error(\"No samples available for visualization.\")\n",
    "                return\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get samples for visualization: {e}\")\n",
    "            return\n",
    "\n",
    "    # Step 4: Plot results\n",
    "    try:\n",
    "        num_samples = len(all_preds)\n",
    "        if num_samples == 0:\n",
    "            logging.warning(\"No predictions to plot.\")\n",
    "            return\n",
    "\n",
    "        fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples), squeeze=False)\n",
    "        fig.suptitle(f'Prediction Analysis: {cfg.EXPERIMENT_NAME}', fontsize=18, fontweight='bold')\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            try:\n",
    "                pred = all_preds[i].squeeze().numpy()\n",
    "                target = all_targets[i].squeeze().numpy()\n",
    "                group = all_groups[i] if i < len(all_groups) else \"Unknown\"\n",
    "\n",
    "                # Validate data\n",
    "                if pred.size == 0 or target.size == 0:\n",
    "                    logging.warning(f\"Empty data for sample {i}, skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Calculate dynamic color range\n",
    "                vmin, vmax = np.percentile(target, [1, 99])\n",
    "                if vmin == vmax:  # Handle constant images\n",
    "                    vmin, vmax = target.min(), target.max()\n",
    "                    if vmin == vmax:\n",
    "                        vmin, vmax = vmin - 0.1, vmax + 0.1\n",
    "\n",
    "                # Ground truth\n",
    "                axes[i, 0].imshow(target, cmap='seismic', vmin=vmin, vmax=vmax)\n",
    "                axes[i, 0].set_ylabel(f\"Group: {group}\", fontsize=12, rotation=90, labelpad=20)\n",
    "                if i == 0:\n",
    "                    axes[i, 0].set_title(\"Ground Truth\", fontsize=14)\n",
    "\n",
    "                # Prediction\n",
    "                axes[i, 1].imshow(pred, cmap='seismic', vmin=vmin, vmax=vmax)\n",
    "                if i == 0:\n",
    "                    axes[i, 1].set_title(\"Prediction\", fontsize=14)\n",
    "\n",
    "                # Difference\n",
    "                diff = np.abs(target - pred)\n",
    "                diff_im = axes[i, 2].imshow(diff, cmap='hot')\n",
    "                if i == 0:\n",
    "                    axes[i, 2].set_title(\"Absolute Difference\", fontsize=14)\n",
    "\n",
    "                fig.colorbar(diff_im, ax=axes[i, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "                # Remove ticks\n",
    "                for ax in axes[i]:\n",
    "                    ax.set_xticks([])\n",
    "                    ax.set_yticks([])\n",
    "\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Failed to plot sample {i}: {e}\")\n",
    "                continue\n",
    "\n",
    "        plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "        output_path = output_dir / f\"{cfg.EXPERIMENT_NAME}_predictions.png\"\n",
    "        plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        logging.info(f\"Validation predictions saved to {output_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to create visualization plot: {e}\")\n",
    "        plt.close('all')  # Clean up any open figures"
   ],
   "id": "94bb74fc883fe496"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def export_to_onnx(model: nn.Module, sample_input: torch.Tensor, output_path: Path) -> None:\n",
    "    \"\"\"Export model to ONNX format\"\"\"\n",
    "    model.eval()\n",
    "    try:\n",
    "        torch.onnx.export(\n",
    "            model,\n",
    "            sample_input,\n",
    "            str(output_path),\n",
    "            opset_version=cfg.ONNX_OPSET_VERSION,\n",
    "            input_names=['seismic'],\n",
    "            output_names=['velocity'],\n",
    "            dynamic_axes={\n",
    "                'seismic': {0: 'batch_size'},\n",
    "                'velocity': {0: 'batch_size'}\n",
    "            }\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"ONNX export failed: {e}\")"
   ],
   "id": "6b609ca67eba90d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loss Function",
   "id": "ce04be2c632c0590"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class CombinedLoss(nn.Module):\n",
    "    \"\"\"Combined loss function with Huber, gradient, and total variation terms,\n",
    "       returning unreduced (per-pixel) loss for group-based weighting.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        huber_w: float = cfg.HUBER_LOSS_WEIGHT,\n",
    "        grad_w: float = cfg.GRAD_LOSS_WEIGHT,\n",
    "        tv_w: float = cfg.TV_LOSS_WEIGHT,\n",
    "        device: torch.device = torch.device('cpu')\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize combined loss.\n",
    "\n",
    "        Args:\n",
    "            huber_w: Weight for Huber loss\n",
    "            grad_w: Weight for gradient loss\n",
    "            tv_w: Weight for total variation loss\n",
    "            device: Target device\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.huber_w = huber_w\n",
    "        self.grad_w = grad_w\n",
    "        self.tv_w = tv_w\n",
    "        self.device = device\n",
    "\n",
    "        # Change reduction to 'none' to return per-pixel loss\n",
    "        self.huber = nn.HuberLoss(reduction='none')\n",
    "\n",
    "        # Initialize Sobel filters for gradient loss - register as buffers for device handling\n",
    "        sobel_x_kernel = torch.tensor([\n",
    "            [-1, 0, 1],\n",
    "            [-2, 0, 2],\n",
    "            [-1, 0, 1]\n",
    "        ], dtype=torch.float32).view(1, 1, 3, 3)\n",
    "\n",
    "        sobel_y_kernel = torch.tensor([\n",
    "            [-1, -2, -1],\n",
    "            [0, 0, 0],\n",
    "            [1, 2, 1]\n",
    "        ], dtype=torch.float32).view(1, 1, 3, 3)\n",
    "\n",
    "        # Register as buffers so they move with the module\n",
    "        self.register_buffer('sobel_x', sobel_x_kernel.repeat(cfg.OUTPUT_CHANNELS, 1, 1, 1))\n",
    "        self.register_buffer('sobel_y', sobel_y_kernel.repeat(cfg.OUTPUT_CHANNELS, 1, 1, 1))\n",
    "\n",
    "    def gradient_loss(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate gradient matching loss (per-pixel).\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted tensor (B, C, H, W)\n",
    "            target: Target tensor (B, C, H, W)\n",
    "\n",
    "        Returns:\n",
    "            Gradient loss tensor (B, C, H, W)\n",
    "        \"\"\"\n",
    "        # Cast filters to match the input's dtype (e.g., bfloat16)\n",
    "        sobel_x = self.sobel_x.to(device=pred.device, dtype=pred.dtype)\n",
    "        sobel_y = self.sobel_y.to(device=pred.device, dtype=pred.dtype)\n",
    "\n",
    "        pred_grad_x = F.conv2d(\n",
    "            pred, sobel_x,\n",
    "            padding=1,\n",
    "            groups=cfg.OUTPUT_CHANNELS\n",
    "        )\n",
    "        pred_grad_y = F.conv2d(\n",
    "            pred, sobel_y,\n",
    "            padding=1,\n",
    "            groups=cfg.OUTPUT_CHANNELS\n",
    "        )\n",
    "\n",
    "        target_grad_x = F.conv2d(\n",
    "            target, sobel_x,\n",
    "            padding=1,\n",
    "            groups=cfg.OUTPUT_CHANNELS\n",
    "        )\n",
    "        target_grad_y = F.conv2d(\n",
    "            target, sobel_y,\n",
    "            padding=1,\n",
    "            groups=cfg.OUTPUT_CHANNELS\n",
    "        )\n",
    "\n",
    "        # Use reduction='none' for per-pixel gradient loss\n",
    "        return F.l1_loss(pred_grad_x, target_grad_x, reduction='none') + \\\n",
    "               F.l1_loss(pred_grad_y, target_grad_y, reduction='none')\n",
    "\n",
    "    def tv_loss(self, pred: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate total variation loss per sample for noise reduction.\n",
    "        This returns a (B, 1, 1, 1) tensor to be broadcasted.\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted tensor (B, C, H, W)\n",
    "\n",
    "        Returns:\n",
    "            TV loss tensor (B, 1, 1, 1)\n",
    "        \"\"\"\n",
    "        # Calculate horizontal and vertical differences\n",
    "        diff_h = torch.abs(pred[..., :, :-1] - pred[..., :, 1:])\n",
    "        diff_v = torch.abs(pred[..., :-1, :] - pred[..., 1:, :])\n",
    "\n",
    "        # Sum differences across spatial dimensions for each channel, then sum channels\n",
    "        # This gives a TV value for each image in the batch (B, C) -> sum(C) -> (B,)\n",
    "        tv_per_sample = diff_h.sum(dim=(-1, -2)).sum(dim=-1) + \\\n",
    "                        diff_v.sum(dim=(-1, -2)).sum(dim=-1)\n",
    "\n",
    "        # Normalize by number of pixels to make it less dependent on image size,\n",
    "        # then reshape for broadcasting\n",
    "        num_pixels = pred.shape[-1] * pred.shape[-2]\n",
    "        # Keepdim=True to maintain original dims if wanted. Here we want (B, 1, 1, 1)\n",
    "        return (tv_per_sample / num_pixels).view(-1, 1, 1, 1)\n",
    "\n",
    "    def forward(self, pred: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculate combined loss (per-pixel).\n",
    "\n",
    "        Args:\n",
    "            pred: Predicted tensor (B, C, H, W)\n",
    "            target: Target tensor (B, C, H, W)\n",
    "\n",
    "        Returns:\n",
    "            Combined loss tensor (B, C, H, W)\n",
    "        \"\"\"\n",
    "        # Input validation\n",
    "        if pred.shape != target.shape:\n",
    "            raise ValueError(f\"Prediction and target shapes must match: {pred.shape} vs {target.shape}\")\n",
    "\n",
    "        if torch.isnan(pred).any() or torch.isnan(target).any():\n",
    "            raise ValueError(\"NaN values detected in input tensors\")\n",
    "\n",
    "        # Calculate individual loss components\n",
    "        huber_loss_unreduced = self.huber(pred, target)  # (B, C, H, W)\n",
    "        grad_loss_unreduced = self.gradient_loss(pred, target)  # (B, C, H, W)\n",
    "\n",
    "        # TV loss per sample, then broadcast\n",
    "        total_variation_loss_per_sample = self.tv_loss(pred)  # (B, 1, 1, 1)\n",
    "        total_variation_loss_broadcasted = total_variation_loss_per_sample.expand_as(huber_loss_unreduced)\n",
    "\n",
    "        # Combine with weights\n",
    "        combined_unreduced_loss = (\n",
    "            self.huber_w * huber_loss_unreduced +\n",
    "            self.grad_w * grad_loss_unreduced +\n",
    "            self.tv_w * total_variation_loss_broadcasted\n",
    "        )\n",
    "\n",
    "        return combined_unreduced_loss  # (B, C, H, W)"
   ],
   "id": "850446b6f98a04a9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training and Validation Loops",
   "id": "687e311df3adc27d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    criterion: CombinedLoss,\n",
    "    scaler: torch.cuda.amp.GradScaler,\n",
    "    ema: ModelEMA,\n",
    "    scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
    "    batch_processor: GPUBatchProcessor,\n",
    "    ddp_manager: DDPManager,\n",
    "    amp_dtype: torch.dtype,\n",
    "    class_weights: Optional[Dict[str, float]],\n",
    "    restart_monitor: Optional[WarmRestartMonitor] = None,\n",
    "    profiler: Optional[torch.profiler.profile] = None\n",
    ") -> Tuple[float, float, float]:\n",
    "    \"\"\"\n",
    "    Train model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: Model to train\n",
    "        loader: Training DataLoader\n",
    "        optimizer: Optimizer\n",
    "        criterion: Loss function\n",
    "        scaler: Gradient scaler for AMP\n",
    "        ema: EMA model\n",
    "        scheduler: Learning rate scheduler\n",
    "        batch_processor: Batch processing utility\n",
    "        ddp_manager: DDP manager\n",
    "        amp_dtype: AMP data type\n",
    "        class_weights: Class weights for loss\n",
    "        profiler: Optional profiler\n",
    "\n",
    "    Returns:\n",
    "        Tuple of (average_loss, average_mae, average_gradient_norm)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    total_loss, total_denorm_mae, total_grad_norm = 0.0, 0.0, 0.0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "    pbar = tqdm(enumerate(loader), total=len(loader), desc=\"Training\",\n",
    "                leave=False, disable=(not ddp_manager.is_main_process()))\n",
    "\n",
    "    for i, (seismic, velocity, groups) in pbar:\n",
    "        # Convert to channels-last format\n",
    "        seismic = seismic.to(memory_format=torch.channels_last)\n",
    "\n",
    "        # Process batch (normalization + augmentations)\n",
    "        norm_seismic, norm_velocity, denorm_velocity = batch_processor.process_batch(\n",
    "            seismic, velocity, groups, is_train=True\n",
    "        )\n",
    "\n",
    "        # Forward pass with AMP\n",
    "        with torch.cuda.amp.autocast(enabled=cfg.USE_AMP, dtype=amp_dtype):\n",
    "            preds_norm = model(norm_seismic)\n",
    "\n",
    "            # Calculate combined loss (per pixel)\n",
    "            per_pixel_loss = criterion(preds_norm, norm_velocity)\n",
    "\n",
    "            # Apply class weights if enabled\n",
    "            if cfg.USE_LOSS_WEIGHTING and class_weights:\n",
    "                # Handle missing groups gracefully\n",
    "                weights = []\n",
    "                for g in groups:\n",
    "                    if g in class_weights:\n",
    "                        weights.append(class_weights[g])\n",
    "                    else:\n",
    "                        logging.warning(f\"Group '{g}' not found in class_weights, using weight 1.0\")\n",
    "                        weights.append(1.0)\n",
    "\n",
    "                weights_tensor = torch.tensor(weights, device=ddp_manager.device, dtype=torch.float32)\n",
    "                weights_tensor = weights_tensor.view(-1, 1, 1, 1)  # Reshape for broadcasting\n",
    "                loss = (per_pixel_loss * weights_tensor).mean()  # Apply weights and then take mean\n",
    "            else:\n",
    "                loss = per_pixel_loss.mean()  # Just take mean if no weighting\n",
    "\n",
    "        # Backward pass with gradient accumulation\n",
    "        scaler.scale(loss / cfg.ACCUMULATION_STEPS).backward()\n",
    "\n",
    "        # Gradient accumulation step\n",
    "        if (i + 1) % cfg.ACCUMULATION_STEPS == 0:\n",
    "            scaler.unscale_(optimizer)\n",
    "\n",
    "            # Check for finite gradients\n",
    "            is_finite = all(\n",
    "                torch.isfinite(p.grad).all()\n",
    "                for p in model.parameters()\n",
    "                if p.grad is not None\n",
    "            )\n",
    "\n",
    "            if is_finite:\n",
    "                # Gradient clipping\n",
    "                grad_norm = torch.nn.utils.clip_grad_norm_(\n",
    "                    model.parameters(),\n",
    "                    max_norm=cfg.GRAD_CLIP_NORM\n",
    "                )\n",
    "                total_grad_norm += grad_norm.item()\n",
    "\n",
    "                # Optimizer step\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "            else:\n",
    "                logging.warning(f\"Skipping optimizer step at iteration {i+1} due to non-finite gradients.\")\n",
    "\n",
    "            # Update scheduler and reset gradients\n",
    "            scheduler.step()\n",
    "\n",
    "            # Monitor warm restarts if enabled\n",
    "            if restart_monitor is not None:\n",
    "                current_lr = optimizer.param_groups[0]['lr']\n",
    "                restart_monitor.check_restart(current_lr)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        # Update EMA model\n",
    "        ema.update(model.module if ddp_manager.is_ddp else model)\n",
    "\n",
    "        # Update metrics\n",
    "        loss_val = loss.item()\n",
    "        if not math.isfinite(loss_val):\n",
    "            logging.warning(f\"Non-finite loss detected at iteration {i+1}: {loss_val}\")\n",
    "            continue\n",
    "\n",
    "        total_loss += loss_val\n",
    "        with torch.no_grad():\n",
    "            denorm_preds = batch_processor.denormalize(preds_norm)\n",
    "            mae_val = F.l1_loss(denorm_preds, denorm_velocity).item()\n",
    "            if math.isfinite(mae_val):\n",
    "                total_denorm_mae += mae_val\n",
    "\n",
    "        # Update progress bar\n",
    "        if ddp_manager.is_main_process():\n",
    "            pbar.set_postfix(loss=f\"{loss.item():.4f}\")\n",
    "\n",
    "        # Profiler step\n",
    "        if profiler:\n",
    "            profiler.step()\n",
    "\n",
    "    # Calculate epoch averages\n",
    "    num_steps = max(1, len(loader) // cfg.ACCUMULATION_STEPS)  # Prevent division by zero\n",
    "    return (\n",
    "        total_loss / len(loader),\n",
    "        total_denorm_mae / len(loader),\n",
    "        total_grad_norm / num_steps\n",
    "    )"
   ],
   "id": "4f65f019d3290af1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def validate_one_epoch(\n",
    "    model: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    metrics: Dict[str, MeanAbsoluteError],\n",
    "    batch_processor: GPUBatchProcessor,\n",
    "    ddp_manager: DDPManager,\n",
    "    amp_dtype: torch.dtype\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Validate model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model: Model to validate\n",
    "        loader: Validation DataLoader\n",
    "        metrics: Dictionary of metric trackers\n",
    "        batch_processor: Batch processing utility\n",
    "        ddp_manager: DDP manager\n",
    "        amp_dtype: AMP data type\n",
    "\n",
    "    Returns:\n",
    "        Dictionary of validation metrics\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    pbar = tqdm(loader, desc=\"Validating\", leave=False,\n",
    "                disable=(not ddp_manager.is_main_process()))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seismic, velocity, groups in pbar:\n",
    "            # Convert to channels-last format\n",
    "            seismic = seismic.to(memory_format=torch.channels_last)\n",
    "\n",
    "            # Process batch\n",
    "            norm_seismic, norm_velocity, denorm_vel = batch_processor.process_batch(\n",
    "                seismic, velocity, groups, is_train=False\n",
    "            )\n",
    "\n",
    "            # Forward pass with AMP\n",
    "            with torch.cuda.amp.autocast(enabled=cfg.USE_AMP, dtype=amp_dtype):\n",
    "                norm_preds = model(norm_seismic)\n",
    "\n",
    "            # Denormalize predictions\n",
    "            denorm_preds = batch_processor.denormalize(norm_preds)\n",
    "\n",
    "            # Update metrics per group\n",
    "            for i, group in enumerate(groups):\n",
    "                pred = denorm_preds[i:i+1]\n",
    "                target_d = denorm_vel[i:i+1]\n",
    "                target_n = norm_velocity[i:i+1]\n",
    "\n",
    "                metrics[f\"val_{group}_loss\"].update(norm_preds[i:i+1], target_n)\n",
    "                metrics[f\"val_{group}_mae\"].update(pred, target_d)\n",
    "                metrics[f\"val_{group}_ssim\"].update(\n",
    "                    rescale_to_unit_range(pred),\n",
    "                    rescale_to_unit_range(target_d)\n",
    "                )\n",
    "\n",
    "    # Compute and reset metrics\n",
    "    results = {key: metric.compute().item() for key, metric in metrics.items()}\n",
    "    for metric in metrics.values():\n",
    "        metric.reset()\n",
    "\n",
    "    return results\n"
   ],
   "id": "a5f9b87f66881f20"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Main Execution",
   "id": "7b30af8c42837797"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main() -> None:\n",
    "    \"\"\"Main training pipeline\"\"\"\n",
    "    # Initialize distributed training\n",
    "    ddp_manager = DDPManager()\n",
    "\n",
    "    try:\n",
    "        # Main process setup\n",
    "        if ddp_manager.is_main_process():\n",
    "            # Check GPU status\n",
    "            subprocess.run([\"nvidia-smi\"])\n",
    "\n",
    "            # Create output directory\n",
    "            os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "            # Setup logging\n",
    "            log_file = cfg.OUTPUT_DIR / f\"{cfg.EXPERIMENT_NAME}_{datetime.datetime.now().strftime('%Y%m%d')}.log\"\n",
    "            setup_logging(log_file)\n",
    "\n",
    "            logging.info(f\"--- Starting Experiment: {cfg.EXPERIMENT_NAME} ---\")\n",
    "            logging.info(f\"Mode: {'DDP' if ddp_manager.is_ddp else 'Single-GPU'} | World Size: {ddp_manager.world_size}\")\n",
    "\n",
    "            try:\n",
    "                cfg.validate()\n",
    "            except (AssertionError, FileNotFoundError) as e:\n",
    "                logging.error(f\"Config validation failed: {e}\")\n",
    "                return\n",
    "\n",
    "        # Validate DDP setup\n",
    "        validate_ddp_setup(ddp_manager)\n",
    "\n",
    "        # Set random seeds\n",
    "        set_seed(cfg.RANDOM_SEED)\n",
    "\n",
    "        # Scan and split dataset files\n",
    "        file_pairs = scan_files(cfg.TRAIN_PATH)\n",
    "        train_pairs, val_pairs = create_stratified_split(file_pairs, cfg.VALIDATION_SPLIT)\n",
    "\n",
    "        # Calculate class weights if needed\n",
    "        class_weights = calculate_class_weights(train_pairs, ddp_manager)\n",
    "\n",
    "        # Set seed again with rank offset\n",
    "        set_seed(cfg.RANDOM_SEED, rank=ddp_manager.rank)\n",
    "\n",
    "        # Log dataset info\n",
    "        if ddp_manager.is_main_process():\n",
    "            log_dataset_info(train_pairs, val_pairs)\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = FWIDataset(train_pairs, device=ddp_manager.device)\n",
    "        val_dataset = FWIDataset(val_pairs, device=ddp_manager.device)\n",
    "\n",
    "        # Create distributed samplers if using DDP\n",
    "        train_sampler = (DistributedSampler(\n",
    "            train_dataset,\n",
    "            num_replicas=ddp_manager.world_size,\n",
    "            rank=ddp_manager.rank,\n",
    "            shuffle=True\n",
    "        ) if ddp_manager.is_ddp else None)\n",
    "\n",
    "        # Determine optimal number of workers based on available memory\n",
    "        available_memory_gb = psutil.virtual_memory().available / (1024**3)\n",
    "        max_workers_by_memory = int(available_memory_gb / cfg.MEMORY_WORKERS_RATIO)\n",
    "        optimal_workers = min(\n",
    "            cfg.NUM_WORKERS,\n",
    "            os.cpu_count() // (ddp_manager.world_size if ddp_manager.world_size > 0 else 1),\n",
    "            max_workers_by_memory\n",
    "        )\n",
    "\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(f\"Using {optimal_workers} workers per DataLoader process.\")\n",
    "\n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(\n",
    "            train_dataset,\n",
    "            batch_size=cfg.BATCH_SIZE,\n",
    "            sampler=train_sampler,\n",
    "            shuffle=(train_sampler is None),\n",
    "            num_workers=optimal_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            prefetch_factor=4 if optimal_workers > 0 else 2,\n",
    "            worker_init_fn=seed_worker,\n",
    "            multiprocessing_context='fork' if sys.platform != 'win32' else None,\n",
    "            drop_last=True\n",
    "        )\n",
    "\n",
    "        val_sampler = (DistributedSampler(\n",
    "            val_dataset,\n",
    "            num_replicas=ddp_manager.world_size,\n",
    "            rank=ddp_manager.rank,\n",
    "            shuffle=False\n",
    "        ) if ddp_manager.is_ddp else None)\n",
    "\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=cfg.BATCH_SIZE*cfg.VALIDATION_BATCH_MULTIPLIER,\n",
    "            sampler=val_sampler,\n",
    "            num_workers=optimal_workers,\n",
    "            pin_memory=True,\n",
    "            persistent_workers=True,\n",
    "            prefetch_factor=4 if optimal_workers > 0 else 2\n",
    "        )\n",
    "\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(f\"DataLoaders created. Train batches per GPU: {len(train_loader)}\")\n",
    "\n",
    "        # Initialize model\n",
    "        model = MultiSourceUNetSwin(ddp_manager=ddp_manager).to(ddp_manager.device)\n",
    "        model = model.to(memory_format=torch.channels_last)\n",
    "\n",
    "        # Validate model outputs\n",
    "        if ddp_manager.is_main_process():\n",
    "            sample_input = torch.randn(2, cfg.NUM_SOURCES, cfg.INPUT_HEIGHT, cfg.INPUT_WIDTH)\n",
    "            validate_model_outputs(model, sample_input, ddp_manager.device)\n",
    "\n",
    "        # Compile model for optimization (before DDP wrapping)\n",
    "        if cfg.USE_TORCH_COMPILE and hasattr(torch, 'compile'):\n",
    "            if ddp_manager.is_main_process():\n",
    "                logging.info(f\"Compiling model with torch.compile (mode: {cfg.COMPILE_MODE})...\")\n",
    "            try:\n",
    "                model = torch.compile(model, mode=cfg.COMPILE_MODE)\n",
    "                if ddp_manager.is_main_process():\n",
    "                    logging.info(\"Model compilation successful.\")\n",
    "            except Exception as e:\n",
    "                if ddp_manager.is_main_process():\n",
    "                    logging.warning(f\"Model compilation failed: {e}. Continuing without compilation.\")\n",
    "\n",
    "        # Enable FlashAttention if available\n",
    "        if torch.cuda.is_available():\n",
    "            torch.backends.cuda.enable_flash_sdp(True)\n",
    "\n",
    "        # Determine AMP dtype\n",
    "        amp_dtype = torch.bfloat16 if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else torch.float16\n",
    "\n",
    "        # Check for fused AdamW optimizer\n",
    "        use_fused_optimizer = torch.cuda.is_available()\n",
    "        try:\n",
    "            _ = torch.optim.AdamW([torch.tensor(0)], lr=1e-4, fused=True)\n",
    "        except (RuntimeError, TypeError):\n",
    "            use_fused_optimizer = False\n",
    "\n",
    "        # Initialize optimizer\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(),\n",
    "            lr=cfg.LEARNING_RATE,\n",
    "            weight_decay=cfg.WEIGHT_DECAY,\n",
    "            fused=use_fused_optimizer\n",
    "        )\n",
    "\n",
    "        # Initialize training components\n",
    "        aug_scheduler = AdaptiveAugmentation()\n",
    "\n",
    "        criterion = CombinedLoss(\n",
    "            huber_w=cfg.HUBER_LOSS_WEIGHT,\n",
    "            grad_w=cfg.GRAD_LOSS_WEIGHT,\n",
    "            tv_w=cfg.TV_LOSS_WEIGHT,\n",
    "            device=ddp_manager.device\n",
    "        )\n",
    "\n",
    "        ema = ModelEMA(model, decay=cfg.EMA_DECAY).to(ddp_manager.device)\n",
    "\n",
    "        # Compile EMA model for validation optimization\n",
    "        if cfg.USE_TORCH_COMPILE and hasattr(torch, 'compile'):\n",
    "            try:\n",
    "                ema.ema_model = torch.compile(ema.ema_model, mode=cfg.COMPILE_MODE)\n",
    "                if ddp_manager.is_main_process():\n",
    "                    logging.info(\"EMA model compilation successful.\")\n",
    "            except Exception as e:\n",
    "                if ddp_manager.is_main_process():\n",
    "                    logging.warning(f\"EMA model compilation failed: {e}. Continuing without compilation.\")\n",
    "\n",
    "        scheduler = get_scheduler(optimizer, train_loader)\n",
    "\n",
    "        # Validate scheduler configuration\n",
    "        if ddp_manager.is_main_process():\n",
    "            validate_scheduler_config(train_loader)\n",
    "\n",
    "        # Initialize restart monitor for warm restarts\n",
    "        restart_monitor = WarmRestartMonitor() if cfg.USE_WARM_RESTARTS else None\n",
    "\n",
    "        # Resume from checkpoint if specified\n",
    "        start_epoch = 0\n",
    "        history = defaultdict(list) # Initialize history\n",
    "        if cfg.RESUME_CHECKPOINT:\n",
    "            if ddp_manager.is_main_process():\n",
    "                logging.info(f\"Resuming from checkpoint: {cfg.RESUME_CHECKPOINT}\")\n",
    "\n",
    "            # Capture the returned history from load_checkpoint\n",
    "            returned_start_epoch, loaded_history = load_checkpoint(\n",
    "                Path(cfg.RESUME_CHECKPOINT),\n",
    "                model,\n",
    "                optimizer,\n",
    "                scheduler,\n",
    "                ema,\n",
    "                ddp_manager\n",
    "            )\n",
    "            start_epoch = returned_start_epoch\n",
    "            history.update(loaded_history)\n",
    "\n",
    "        # Wrap model in DDP if using distributed training\n",
    "        if ddp_manager.is_ddp:\n",
    "            safe_barrier(ddp_manager)\n",
    "            model = DDP(\n",
    "                model,\n",
    "                device_ids=[ddp_manager.rank % torch.cuda.device_count()],\n",
    "                find_unused_parameters=False\n",
    "            )\n",
    "\n",
    "        # Model summary and metrics setup\n",
    "        metrics_logger = None\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(\"--- Model & Training Setup ---\")\n",
    "            summary(\n",
    "                model,\n",
    "                input_size=(cfg.BATCH_SIZE, cfg.NUM_SOURCES, cfg.INPUT_HEIGHT, cfg.INPUT_WIDTH),\n",
    "                device=ddp_manager.device,\n",
    "                depth=5\n",
    "            )\n",
    "            metrics_logger = MetricsLogger(log_dir=cfg.OUTPUT_DIR / 'tensorboard')\n",
    "\n",
    "        # Training components (all processes need these)\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=cfg.USE_AMP)\n",
    "        early_stopper = EarlyStopping(verbose=ddp_manager.is_main_process())\n",
    "        batch_processor = GPUBatchProcessor(\n",
    "            device=ddp_manager.device,\n",
    "            aug_scheduler=aug_scheduler\n",
    "        )\n",
    "\n",
    "        # Initialize validation metrics\n",
    "        validation_metrics = {}\n",
    "        for group in [\"Vel\", \"Style\", \"Fault\"]:\n",
    "            for metric_name, metric_class in [\n",
    "                (\"loss\", MeanAbsoluteError),\n",
    "                (\"mae\", MeanAbsoluteError),\n",
    "                (\"ssim\", StructuralSimilarityIndexMeasure)\n",
    "            ]:\n",
    "                key = f\"val_{group}_{metric_name}\"\n",
    "                params = {'data_range': 1.0} if metric_name == \"ssim\" else {}\n",
    "                validation_metrics[key] = metric_class(**params).to(ddp_manager.device)\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Profiler setup\n",
    "        profiler_context = (\n",
    "            torch.profiler.profile(\n",
    "                schedule=torch.profiler.schedule(wait=1, warmup=1, active=3, repeat=2),\n",
    "                on_trace_ready=torch.profiler.tensorboard_trace_handler(str(cfg.OUTPUT_DIR / 'profiler')),\n",
    "                record_shapes=True,\n",
    "                with_stack=True\n",
    "            ) if cfg.RUN_PROFILER and ddp_manager.is_main_process() else contextlib.nullcontext()\n",
    "        )\n",
    "\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(f\"Starting training from epoch {start_epoch+1}...\")\n",
    "\n",
    "        # Training loop\n",
    "        with profiler_context as profiler:\n",
    "            for epoch in range(start_epoch, cfg.NUM_EPOCHS):\n",
    "                epoch_start_time = time.time()\n",
    "\n",
    "                # Set epoch for distributed sampler\n",
    "                if ddp_manager.is_ddp:\n",
    "                    train_sampler.set_epoch(epoch)\n",
    "\n",
    "                # Train for one epoch\n",
    "                train_loss, train_mae, grad_norm = train_one_epoch(\n",
    "                    model, train_loader, optimizer, criterion, scaler,\n",
    "                    ema, scheduler, batch_processor, ddp_manager,\n",
    "                    amp_dtype, class_weights, restart_monitor, profiler\n",
    "                )\n",
    "\n",
    "                # Validate\n",
    "                val_results = validate_one_epoch(\n",
    "                    ema.ema_model, val_loader, validation_metrics,\n",
    "                    batch_processor, ddp_manager, amp_dtype\n",
    "                )\n",
    "\n",
    "                # Main process logging and checkpointing\n",
    "                if ddp_manager.is_main_process():\n",
    "                    # Update augmentation strength\n",
    "                    avg_val_loss = val_results.get(f\"val_Vel_loss\", float('nan'))\n",
    "                    if not math.isnan(avg_val_loss):\n",
    "                        aug_scheduler.update(avg_val_loss)\n",
    "\n",
    "                    # Get current gradient scale\n",
    "                    current_scale = scaler.get_scale()\n",
    "\n",
    "                    # Prepare epoch metrics\n",
    "                    epoch_metrics = {\n",
    "                        'train/loss': train_loss,\n",
    "                        'train/mae': train_mae,\n",
    "                        'train/grad_norm': grad_norm,\n",
    "                        'train/lr': optimizer.param_groups[0]['lr'],\n",
    "                        'train/grad_scaler': current_scale\n",
    "                    }\n",
    "\n",
    "                    # Update history\n",
    "                    history['train_loss'].append(train_loss)\n",
    "                    history['train_denorm_mae'].append(train_mae)\n",
    "                    history['grad_norm'].append(grad_norm)\n",
    "                    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "                    # Group-specific metrics\n",
    "                    val_losses, val_maes = [], []\n",
    "                    logging.info(f\"--- Epoch {epoch+1}/{cfg.NUM_EPOCHS} | Time: {time.time()-epoch_start_time:.2f}s ---\")\n",
    "                    logging.info(f\"  Train -> Loss: {train_loss:.4f} | MAE: {train_mae:.2f} | Grad Norm: {grad_norm:.2f}\")\n",
    "\n",
    "                    for group in [\"Vel\", \"Style\", \"Fault\"]:\n",
    "                        loss = val_results.get(f\"val_{group}_loss\", float('nan'))\n",
    "                        mae = val_results.get(f\"val_{group}_mae\", float('nan'))\n",
    "                        ssim = val_results.get(f\"val_{group}_ssim\", float('nan'))\n",
    "\n",
    "                        history[f\"val_{group}_mae\"].append(mae)\n",
    "                        history[f\"val_{group}_ssim\"].append(ssim)\n",
    "\n",
    "                        if not math.isnan(mae):\n",
    "                            val_maes.append(mae)\n",
    "\n",
    "                        logging.info(f\"  - Val {group:<5} -> Loss: {loss:.4f} | MAE: {mae:.2f} | SSIM: {ssim:.4f}\")\n",
    "\n",
    "                    # Calculate average validation MAE\n",
    "                    avg_val_mae = sum(val_maes)/len(val_maes) if val_maes else float('nan')\n",
    "                    history['val_avg_mae'].append(avg_val_mae)\n",
    "                    epoch_metrics['val/avg_mae'] = avg_val_mae\n",
    "\n",
    "                    logging.info(f\"  Overall Valid -> Avg MAE: {avg_val_mae:.2f}\")\n",
    "\n",
    "                    # Log metrics\n",
    "                    if metrics_logger is not None:\n",
    "                        metrics_logger.log(epoch_metrics, epoch)\n",
    "\n",
    "                    # Early stopping check\n",
    "                    if not math.isnan(avg_val_mae):\n",
    "                        early_stopper(\n",
    "                            avg_val_mae,\n",
    "                            ema.ema_model,\n",
    "                            cfg.OUTPUT_DIR / \"best_model_ema.pth\"\n",
    "                        )\n",
    "\n",
    "                    # Periodic checkpointing\n",
    "                    if (epoch + 1) % cfg.CHECKPOINT_EVERY == 0:\n",
    "                        model_to_save = model.module if ddp_manager.is_ddp else model\n",
    "                        save_checkpoint(\n",
    "                            epoch,\n",
    "                            model_to_save,\n",
    "                            optimizer,\n",
    "                            scheduler,\n",
    "                            ema,\n",
    "                            cfg.OUTPUT_DIR / f\"checkpoint_epoch_{epoch+1}.pth\",\n",
    "                            history,\n",
    "                            ddp_manager\n",
    "                        )\n",
    "\n",
    "                    # Break if early stopping triggered\n",
    "                    if early_stopper.early_stop:\n",
    "                        logging.info(\"Early stopping triggered.\")\n",
    "                        break\n",
    "\n",
    "                # Broadcast stop signal to all processes\n",
    "                if ddp_manager.is_ddp:\n",
    "                    stop_tensor = torch.tensor(int(early_stopper.early_stop), device=ddp_manager.device)\n",
    "                    dist.broadcast(stop_tensor, src=0)\n",
    "                    if stop_tensor.item() == 1:\n",
    "                        break\n",
    "\n",
    "        # Final cleanup and logging\n",
    "        safe_barrier(ddp_manager)\n",
    "\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(f\"--- Training Complete | Total Time: {(time.time()-start_time)/3600:.2f} hours ---\")\n",
    "            best_model_path = cfg.OUTPUT_DIR / \"best_model_ema.pth\"\n",
    "\n",
    "            if best_model_path.exists():\n",
    "                logging.info(f\"Best validation MAE achieved: {early_stopper.best_score:.4f}\")\n",
    "\n",
    "                # Load best model for final evaluation\n",
    "                final_model = MultiSourceUNetSwin(ddp_manager=ddp_manager)\n",
    "                final_model.load_state_dict(torch.load(best_model_path, map_location=\"cpu\"))\n",
    "                final_model.to(ddp_manager.device)\n",
    "                final_model.to(memory_format=torch.channels_last)\n",
    "\n",
    "                # Generate final plots\n",
    "                plot_metrics(history, cfg.OUTPUT_DIR)\n",
    "                visualize_predictions(final_model, val_loader, batch_processor, cfg.OUTPUT_DIR)\n",
    "\n",
    "                # Export to ONNX if enabled\n",
    "                if cfg.EXPORT_ONNX:\n",
    "                    logging.info(\"--- Exporting model to ONNX ---\")\n",
    "                    sample_input = torch.randn(1, cfg.NUM_SOURCES, cfg.INPUT_HEIGHT, cfg.INPUT_WIDTH, device=ddp_manager.device)\n",
    "                    sample_input = sample_input.to(memory_format=torch.channels_last)\n",
    "                    export_path = cfg.OUTPUT_DIR / f\"{cfg.EXPERIMENT_NAME}.onnx\"\n",
    "                    export_to_onnx(final_model, sample_input, export_path)\n",
    "            else:\n",
    "                logging.warning(\"No best model saved. Skipping final visualizations.\")\n",
    "\n",
    "            # Close metrics logger\n",
    "            if metrics_logger is not None:\n",
    "                metrics_logger.close()\n",
    "\n",
    "            # Log restart summary\n",
    "            if restart_monitor is not None and ddp_manager.is_main_process():\n",
    "                logging.info(f\"ðŸ”„ Warm restart summary: {restart_monitor.restart_count} restarts occurred during training\")\n",
    "\n",
    "    except (KeyboardInterrupt, Exception) as e:\n",
    "        if isinstance(e, KeyboardInterrupt):\n",
    "            logging.warning(\"Training interrupted by user.\")\n",
    "        else:\n",
    "            logging.error(f\"An unexpected error occurred: {e}\", exc_info=True)\n",
    "    finally:\n",
    "        # Cleanup distributed training\n",
    "        ddp_manager.cleanup()\n",
    "        if ddp_manager.is_main_process():\n",
    "            logging.info(\"Cleanup complete. Exiting.\")"
   ],
   "id": "823145e3f1d6458f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "88fd2a8ceb3541af"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Checkpoint Resumption\n",
    "\n",
    "This script was utilized to create the visualizations because there was an error in the DDP process, so the OAR job ended after the training was completed. We utilized the best model checkpoint to create visualizations. (DDP was not required for this process.)"
   ],
   "id": "7d5d4a830068d868"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import logging\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "import timm\n",
    "import argparse\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "import datetime"
   ],
   "id": "da88c14631d8bc4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "id": "ced1744a39c343c6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Configuration (copied exactly from training script)\n",
    "class Config:\n",
    "    # Paths\n",
    "    TRAIN_PATH = Path(\"/tmp/gkhanal-runtime-dir/data/train/openfwi_72x72\")\n",
    "\n",
    "    # Model\n",
    "    MODEL_NAME = 'swinv2_tiny_window8_256.ms_in1k'\n",
    "    PRETRAINED = True\n",
    "    OUTPUT_CHANNELS = 1\n",
    "    NUM_SOURCES = 5\n",
    "    RGB_CHANNELS = 3\n",
    "    STEM_CHANNELS = 32  # Fixed to match training script\n",
    "    GROUPNORM_GROUPS = 8\n",
    "    BACKBONE_INPUT_SIZE = 256\n",
    "    DECODER_CHANNELS = [512, 256, 128]\n",
    "    DECODER_DROPOUT = 0.2\n",
    "\n",
    "    # Model dimensions (copied exactly from training script)\n",
    "    INPUT_HEIGHT = 72                               # Input seismic data height\n",
    "    INPUT_WIDTH = 72                                # Input seismic data width\n",
    "    OUTPUT_HEIGHT = 70                              # Output velocity model height\n",
    "    OUTPUT_WIDTH = 70                               # Output velocity model width\n",
    "    SCSE_REDUCTION = 16                             # Default reduction factor in SCSE block\n",
    "\n",
    "    # Data\n",
    "    RANDOM_SEED = 42\n",
    "    VALIDATION_SPLIT = 0.20\n",
    "    VELOCITY_MIN = 1500.0\n",
    "    VELOCITY_MAX = 4500.0\n",
    "    MIN_STD_CLAMP = 1e-6\n",
    "\n",
    "    # Training\n",
    "    USE_AMP = True\n",
    "\n",
    "    # Experiment\n",
    "    EXPERIMENT_NAME = \"SwinV2_FWI_Visualization\"\n",
    "\n",
    "cfg = Config()"
   ],
   "id": "3d7667f8f5dcc200"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data and Model sections are the same as main script.",
   "id": "530ac03b50b76893"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Simple DDPManager for inference (no DDP)\n",
    "class SimpleDDPManager:\n",
    "    def __init__(self):\n",
    "        self.is_ddp = False\n",
    "\n",
    "    def is_main_process(self) -> bool:\n",
    "        \"\"\"Check if current process is the main process\"\"\"\n",
    "        return True\n",
    "\n",
    "def safe_barrier(ddp_manager):\n",
    "    \"\"\"Safe barrier function (no-op for single GPU)\"\"\"\n",
    "    pass"
   ],
   "id": "9ee4dc8989aae775"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Simple batch processor for validation (matches training script)\n",
    "class SimpleBatchProcessor:\n",
    "    \"\"\"Handles batch preprocessing for validation (no augmentations)\"\"\"\n",
    "\n",
    "    def __init__(self, device: torch.device):\n",
    "        self.device = device\n",
    "        self.velocity_min = torch.tensor(cfg.VELOCITY_MIN, device=device)\n",
    "        self.velocity_range = torch.tensor(cfg.VELOCITY_MAX - cfg.VELOCITY_MIN, device=device)\n",
    "\n",
    "    def process_batch(self, seismic: torch.Tensor, velocity: torch.Tensor = None, groups=None, is_train: bool = False):\n",
    "        \"\"\"Process batch with same normalization as training script\"\"\"\n",
    "        # Transfer to device\n",
    "        seismic = seismic.to(self.device, non_blocking=True)\n",
    "        original_velocity = velocity\n",
    "        if velocity is not None:\n",
    "            velocity = velocity.to(self.device, non_blocking=True)\n",
    "\n",
    "        # Normalize seismic data (same as training)\n",
    "        mean = seismic.mean(dim=(-1, -2), keepdim=True)\n",
    "        std = torch.clamp(seismic.std(dim=(-1, -2), keepdim=True), min=cfg.MIN_STD_CLAMP)\n",
    "        seismic = (seismic - mean) / std\n",
    "\n",
    "        # Handle NaN values\n",
    "        if torch.isnan(seismic).any():\n",
    "            logging.warning(\"NaN values detected in seismic data after normalization. Replacing with zeros.\")\n",
    "            seismic = torch.nan_to_num(seismic)\n",
    "\n",
    "        # Normalize velocity if provided\n",
    "        if velocity is not None:\n",
    "            norm_velocity = (velocity - self.velocity_min) / self.velocity_range\n",
    "            return seismic, norm_velocity, original_velocity.to(self.device) if original_velocity is not None else None\n",
    "\n",
    "        return seismic, None, None\n",
    "\n",
    "    def denormalize(self, norm_vel: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Convert normalized velocity back to original scale\"\"\"\n",
    "        return norm_vel * self.velocity_range + self.velocity_min"
   ],
   "id": "713339f9134befb0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main():\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(description='FWI Model Visualization')\n",
    "    parser.add_argument('--data-path', type=str, default=str(cfg.TRAIN_PATH),\n",
    "                       help='Path to training data directory')\n",
    "    parser.add_argument('--checkpoint-path', type=str, default=None,\n",
    "                       help='Path to model checkpoint')\n",
    "    parser.add_argument('--output-dir', type=str, default='./results',\n",
    "                       help='Output directory for visualizations')\n",
    "    parser.add_argument('--samples-per-group', type=int, default=3,\n",
    "                       help='Number of samples to visualize per group')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Update config with command line arguments\n",
    "    if args.data_path:\n",
    "        cfg.TRAIN_PATH = Path(args.data_path)\n",
    "\n",
    "    # Configure logging to both console and file\n",
    "    output_dir = Path(args.output_dir)\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    log_file = output_dir / f\"visualization_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "\n",
    "    # Clear any existing handlers and configure new ones\n",
    "    for handler in logging.root.handlers[:]:\n",
    "        logging.root.removeHandler(handler)\n",
    "\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s [%(levelname)s] - %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    logging.info(f\"Logging to file: {log_file}\")\n",
    "\n",
    "    # Set same seed as training\n",
    "    set_seed(cfg.RANDOM_SEED)\n",
    "\n",
    "    # 1) Load, scan, split dataset (exact same functions)\n",
    "    logging.info(\"Step 1: Scanning and splitting dataset...\")\n",
    "    file_pairs = scan_files(cfg.TRAIN_PATH)\n",
    "    train_pairs, val_pairs = create_stratified_split(file_pairs, cfg.VALIDATION_SPLIT)\n",
    "\n",
    "    # Log dataset info exactly like training script\n",
    "    log_dataset_info(train_pairs, val_pairs)\n",
    "\n",
    "    # Create validation dataset and loader\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    val_dataset = FWIDataset(val_pairs, device)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "    # 2) Bring model (exact same class)\n",
    "    logging.info(\"Step 2: Creating model...\")\n",
    "    ddp_manager = SimpleDDPManager()\n",
    "    model = MultiSourceUNetSwin(ddp_manager)\n",
    "\n",
    "    # Create batch processor for proper normalization\n",
    "    batch_processor = SimpleBatchProcessor(device)\n",
    "\n",
    "    # 3) Load checkpoint\n",
    "    logging.info(\"Step 3: Loading checkpoint...\")\n",
    "\n",
    "    if args.checkpoint_path:\n",
    "        checkpoint_path = args.checkpoint_path\n",
    "    else:\n",
    "        # Look for common checkpoint names in current directory\n",
    "        possible_paths = [\n",
    "            \"best_model.pth\",\n",
    "            \"best_model_ema.pth\",\n",
    "            \"final_model.pth\",\n",
    "            \"model_checkpoint.pth\"\n",
    "        ]\n",
    "        checkpoint_path = None\n",
    "        for path in possible_paths:\n",
    "            if Path(path).exists():\n",
    "                checkpoint_path = path\n",
    "                break\n",
    "\n",
    "        if checkpoint_path is None:\n",
    "            raise FileNotFoundError(f\"No checkpoint found. Please specify --checkpoint-path or ensure one of these files exists: {possible_paths}\")\n",
    "\n",
    "    if not Path(checkpoint_path).exists():\n",
    "        raise FileNotFoundError(f\"Checkpoint not found: {checkpoint_path}\")\n",
    "\n",
    "    logging.info(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    # Extract and plot training metrics if available\n",
    "    if 'history' in checkpoint:\n",
    "        logging.info(\"Found training history in checkpoint, plotting metrics...\")\n",
    "        history = checkpoint['history']\n",
    "        epoch = checkpoint.get('epoch', len(history.get('train_loss', [])))\n",
    "        logging.info(f\"Training completed at epoch: {epoch + 1}\")\n",
    "\n",
    "        # Plot metrics using the built-in function\n",
    "        output_dir = Path(args.output_dir)\n",
    "        plot_metrics(history, output_dir)\n",
    "        logging.info(f\"Training metrics saved to {output_dir}\")\n",
    "    else:\n",
    "        logging.warning(\"No training history found in checkpoint\")\n",
    "\n",
    "    state_dict = checkpoint.get('model_state_dict', checkpoint)\n",
    "    if any(key.startswith('module.') for key in state_dict.keys()):\n",
    "        state_dict = {key.replace('module.', ''): value for key, value in state_dict.items()}\n",
    "\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # 4) Random sample selection (copied from training script's visualize_predictions)\n",
    "    logging.info(\"Step 4: Selecting random samples for visualization...\")\n",
    "\n",
    "    # Step 1: Pre-select random samples to visualize (with error handling)\n",
    "    grouped_indices = defaultdict(list)\n",
    "    dataset_size = len(val_loader.dataset)\n",
    "    max_samples_to_check = min(1000, dataset_size)  # Limit to avoid long iteration\n",
    "\n",
    "    # Randomly sample indices to check instead of iterating through all\n",
    "    indices_to_check = random.sample(range(dataset_size), max_samples_to_check)\n",
    "\n",
    "    for i in indices_to_check:\n",
    "        try:\n",
    "            _, _, group = val_loader.dataset[i]\n",
    "            grouped_indices[group].append(i)\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to access sample {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    samples_to_plot_indices = []\n",
    "    for group in [\"Vel\", \"Style\", \"Fault\"]:\n",
    "        if len(grouped_indices[group]) > 0:\n",
    "            indices = random.sample(grouped_indices[group], min(args.samples_per_group, len(grouped_indices[group])))\n",
    "            samples_to_plot_indices.extend(indices)\n",
    "            logging.info(f\"Selected {len(indices)} random samples from group {group}\")\n",
    "\n",
    "    if not samples_to_plot_indices:\n",
    "        logging.warning(\"No samples found for visualization. Using first available samples from loader.\")\n",
    "        # Fallback: try to get samples directly from the loader\n",
    "        try:\n",
    "            for batch_idx, (seismic, velocity, groups) in enumerate(val_loader):\n",
    "                if batch_idx == 0:  # Just use first batch\n",
    "                    samples_to_plot_indices = list(range(min(9, len(groups))))\n",
    "                    break\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get samples from loader: {e}\")\n",
    "            return\n",
    "\n",
    "    # Step 2: Get samples for visualization\n",
    "    all_preds, all_targets, all_groups = [], [], []\n",
    "\n",
    "    # Try to use subset if we have valid indices\n",
    "    if samples_to_plot_indices and all(isinstance(idx, int) and 0 <= idx < len(val_loader.dataset) for idx in samples_to_plot_indices):\n",
    "        try:\n",
    "            vis_dataset = Subset(val_loader.dataset, samples_to_plot_indices)\n",
    "            vis_loader = DataLoader(vis_dataset, batch_size=len(samples_to_plot_indices))\n",
    "\n",
    "            # Step 3: Run inference on subset\n",
    "            with torch.no_grad():\n",
    "                for seismic, velocity, groups in vis_loader:\n",
    "                    _, _, denorm_vel = batch_processor.process_batch(seismic, velocity, groups, is_train=False)\n",
    "                    norm_seismic, _, _ = batch_processor.process_batch(seismic, is_train=False)\n",
    "\n",
    "                    with torch.cuda.amp.autocast(enabled=cfg.USE_AMP):\n",
    "                        preds_norm = model(norm_seismic)\n",
    "\n",
    "                    denorm_preds = batch_processor.denormalize(preds_norm).cpu()\n",
    "                    all_preds.append(denorm_preds)\n",
    "                    all_targets.append(denorm_vel.cpu())\n",
    "                    all_groups.extend(groups)\n",
    "\n",
    "            all_preds = torch.cat(all_preds)\n",
    "            all_targets = torch.cat(all_targets)\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to create subset visualization: {e}. Using first batch from loader.\")\n",
    "            all_preds, all_targets, all_groups = [], [], []\n",
    "\n",
    "    # Fallback: use first batch from original loader\n",
    "    if len(all_preds) == 0:\n",
    "        try:\n",
    "            with torch.no_grad():\n",
    "                for seismic, velocity, groups in val_loader:\n",
    "                    # Only take first few samples\n",
    "                    max_vis_samples = min(9, len(groups))\n",
    "                    seismic = seismic[:max_vis_samples]\n",
    "                    velocity = velocity[:max_vis_samples]\n",
    "                    groups = groups[:max_vis_samples]\n",
    "\n",
    "                    _, _, denorm_vel = batch_processor.process_batch(seismic, velocity, groups, is_train=False)\n",
    "                    norm_seismic, _, _ = batch_processor.process_batch(seismic, is_train=False)\n",
    "\n",
    "                    with torch.cuda.amp.autocast(enabled=cfg.USE_AMP):\n",
    "                        preds_norm = model(norm_seismic)\n",
    "\n",
    "                    denorm_preds = batch_processor.denormalize(preds_norm).cpu()\n",
    "                    all_preds.append(denorm_preds)\n",
    "                    all_targets.append(denorm_vel.cpu())\n",
    "                    all_groups.extend(groups)\n",
    "                    break  # Only use first batch\n",
    "\n",
    "            if len(all_preds) > 0:\n",
    "                all_preds = torch.cat(all_preds)\n",
    "                all_targets = torch.cat(all_targets)\n",
    "            else:\n",
    "                logging.error(\"No samples available for visualization.\")\n",
    "                return\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to get samples for visualization: {e}\")\n",
    "            return\n",
    "\n",
    "    # 5) Visualize predictions (same style as training script)\n",
    "    logging.info(\"Step 5: Creating visualizations...\")\n",
    "\n",
    "    num_samples = len(all_preds)\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples), squeeze=False)\n",
    "    fig.suptitle(f'Prediction Analysis: {cfg.EXPERIMENT_NAME}', fontsize=18, fontweight='bold')\n",
    "\n",
    "    for i in range(num_samples):\n",
    "        try:\n",
    "            pred = all_preds[i].squeeze().numpy()\n",
    "            target = all_targets[i].squeeze().numpy()\n",
    "            group = all_groups[i] if i < len(all_groups) else \"Unknown\"\n",
    "\n",
    "            # Validate data\n",
    "            if pred.size == 0 or target.size == 0:\n",
    "                logging.warning(f\"Empty data for sample {i}, skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Validate shapes match (both should be 70x70)\n",
    "            if pred.shape != target.shape:\n",
    "                logging.warning(f\"Shape mismatch for sample {i}: pred={pred.shape}, target={target.shape}\")\n",
    "                continue\n",
    "\n",
    "            # Calculate dynamic color range (same as training script)\n",
    "            vmin, vmax = np.percentile(target, [1, 99])\n",
    "            if vmin == vmax:  # Handle constant images\n",
    "                vmin, vmax = target.min(), target.max()\n",
    "                if vmin == vmax:\n",
    "                    vmin, vmax = vmin - 0.1, vmax + 0.1\n",
    "\n",
    "            # Ground truth\n",
    "            axes[i, 0].imshow(target, cmap='seismic', vmin=vmin, vmax=vmax)\n",
    "            axes[i, 0].set_ylabel(f\"Group: {group}\", fontsize=12, rotation=90, labelpad=20)\n",
    "            if i == 0:\n",
    "                axes[i, 0].set_title(\"Ground Truth\", fontsize=14)\n",
    "\n",
    "            # Prediction\n",
    "            axes[i, 1].imshow(pred, cmap='seismic', vmin=vmin, vmax=vmax)\n",
    "            if i == 0:\n",
    "                axes[i, 1].set_title(\"Prediction\", fontsize=14)\n",
    "\n",
    "            # Difference\n",
    "            diff = np.abs(target - pred)\n",
    "            diff_im = axes[i, 2].imshow(diff, cmap='hot')\n",
    "            if i == 0:\n",
    "                axes[i, 2].set_title(\"Absolute Difference\", fontsize=14)\n",
    "\n",
    "            fig.colorbar(diff_im, ax=axes[i, 2], fraction=0.046, pad=0.04)\n",
    "\n",
    "            # Remove ticks\n",
    "            for ax in axes[i]:\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to plot sample {i}: {e}\")\n",
    "            continue\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    output_path = Path(args.output_dir) / f\"{cfg.EXPERIMENT_NAME}_predictions.png\"\n",
    "    output_path.parent.mkdir(exist_ok=True)\n",
    "    plt.savefig(output_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    logging.info(f\"Validation predictions saved to {output_path}\")\n",
    "\n",
    "    # 6) Done!\n",
    "    logging.info(f\"Step 6: Done! Visualizations saved to {output_path}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "f8c7286302899b98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
