<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>readme</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="README_files/libs/clipboard/clipboard.min.js"></script>
<script src="README_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="README_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="README_files/libs/quarto-html/popper.min.js"></script>
<script src="README_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="README_files/libs/quarto-html/anchor.min.js"></script>
<link href="README_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="README_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="README_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="README_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="README_files/libs/bootstrap/bootstrap-81267100e462c21b3d6c0d5bf76a3417.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="fullcontent quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">




<section id="swinunet-fwi-full-waveform-inversion-with-swin-transformers" class="level1">
<h1>SwinUNet-FWI: Full Waveform Inversion with Swin Transformers</h1>
<p><img src="https://img.shields.io/badge/python-3.8+-blue.svg" class="img-fluid" alt="Python"> <img src="https://img.shields.io/badge/pytorch-2.0+-red.svg" class="img-fluid" alt="PyTorch"> <img src="https://img.shields.io/badge/license-MIT-green.svg" class="img-fluid" alt="License"></p>
<p>This repository contains a high-performance, feature-rich PyTorch pipeline for training a deep learning model for Full-Waveform Inversion (FWI) using the OpenFWI dataset. The model, based on a U-Net architecture with a <strong>Swin Transformer v2</strong> backbone, predicts subsurface velocity models from multi-source seismic data.</p>
<p>The codebase is designed for robustness and performance, incorporating modern deep learning techniques such as Distributed Data Parallel (DDP), <code>torch.compile</code>, mixed-precision training, and advanced data augmentation.</p>
<section id="key-features" class="level2">
<h2 class="anchored" data-anchor-id="key-features">Key Features</h2>
<section id="advanced-model-architecture" class="level3">
<h3 class="anchored" data-anchor-id="advanced-model-architecture">Advanced Model Architecture</h3>
<p>A U-Net style model with a powerful, pretrained Swin Transformer v2 encoder and an enhanced decoder featuring learned upsampling, residual blocks, and SCSE attention.</p>
</section>
<section id="high-performance-training" class="level3">
<h3 class="anchored" data-anchor-id="high-performance-training">High Performance Training</h3>
<ul>
<li><strong>Distributed Data Parallel (DDP)</strong> support for efficient multi-GPU training.</li>
<li><strong>Automatic Mixed Precision (AMP)</strong> with <code>bfloat16</code> for faster training and reduced memory usage.</li>
<li><strong><code>torch.compile</code> Integration</strong>: Leverages PyTorch 2.0+ for significant speedups.</li>
<li><strong>Optimized Data Loading</strong>: High-performance <code>DataLoader</code> with persistent, pre-fetching workers.</li>
</ul>
</section>
<section id="comprehensive-loss-function" class="level3">
<h3 class="anchored" data-anchor-id="comprehensive-loss-function">Comprehensive Loss Function</h3>
<p>The combined loss function is a comprehensive combination of loss functions to provide the best (yet) performance:</p>
<p><span class="math display">\[ \mathcal{L}_{\text{Combined}} = \alpha \cdot \mathcal{L}_{\text{Huber}} + \beta \cdot \mathcal{L}_{\text{Gradient}} + \gamma \cdot \mathcal{L}_{\text{TV}} \]</span></p>
<ul>
<li><strong>Huber loss</strong> for robust regression (i.e., accurate overall reconstruction)</li>
<li><strong>Gradient loss</strong> for structural preservation (i.e., preserve sharp details)</li>
<li><strong>Total variation loss/regularization</strong> for smooth outputs (i.e., smooth out noise without blurring edges)</li>
</ul>
</section>
<section id="state-of-the-art-sota-techniques" class="level3">
<h3 class="anchored" data-anchor-id="state-of-the-art-sota-techniques">State of the Art (SOTA) Techniques</h3>
<ul>
<li><strong>Advanced LR Scheduling</strong>: Cosine Annealing with Warm Restarts and a linear warmup phase.</li>
<li><strong>Exponential Moving Average (EMA)</strong> of model weights for improved generalization.</li>
<li><strong>Gradient Clipping</strong> and accumulation for stable training.</li>
</ul>
</section>
<section id="sophisticated-data-handling" class="level3">
<h3 class="anchored" data-anchor-id="sophisticated-data-handling">Sophisticated Data Handling</h3>
<ul>
<li><strong>Rich GPU-Based Augmentations</strong>: Includes elastic deformation, fault simulation, Gaussian noise, and amplitude jitter.</li>
<li><strong>Adaptive Augmentation</strong>: Dynamically adjusts augmentation strength based on validation performance.</li>
<li><strong>Stratified Data Splitting</strong>: Maintains the proportion of different data groups between training and validation sets.</li>
</ul>
</section>
<section id="comprehensive-experiment-management" class="level3">
<h3 class="anchored" data-anchor-id="comprehensive-experiment-management">Comprehensive Experiment Management</h3>
<ul>
<li><strong>Centralized Configuration</strong>: All parameters are managed in a single <code>Config</code> class.</li>
<li><strong>Robust Checkpointing</strong>: Save and resume training, including optimizer, scheduler, and RNG states.</li>
<li><strong>Detailed Logging</strong>: Logs to console, file, and TensorBoard for real-time monitoring.</li>
<li><strong>Automated Visualization</strong>: Generates plots of training metrics and validation predictions.</li>
<li><strong>ONNX Export</strong>: Easily export the final model for deployment.</li>
</ul>
</section>
</section>
<section id="setup-and-installation" class="level2">
<h2 class="anchored" data-anchor-id="setup-and-installation">Setup and Installation</h2>
<section id="clone-the-repository" class="level3">
<h3 class="anchored" data-anchor-id="clone-the-repository">1. Clone the repository</h3>
<pre><code>git clone https://github.com/gk408829/Geophysical-Full-Waveform-Inversion.git
cd Geophysical-Full-Waveform-Inversion</code></pre>
</section>
<section id="create-a-virtual-environment-recommended" class="level3">
<h3 class="anchored" data-anchor-id="create-a-virtual-environment-recommended">2. Create a virtual environment (recommended):</h3>
<pre><code>python -m venv venv
source venv/bin/activate</code></pre>
</section>
<section id="install-the-required-dependencies" class="level3">
<h3 class="anchored" data-anchor-id="install-the-required-dependencies">3. Install the required dependencies:</h3>
<p>A <code>requirements.txt</code> file can be created with the following contents.</p>
<pre><code># Core DL Framework
torch
torchvision
torchaudio

# Model and Utilities
timm
numpy
psutil
scipy
matplotlib
torchinfo
tqdm
torchmetrics
tensorboard
onnx</code></pre>
<p>Install them using pip:</p>
<pre><code>pip install -r requirements.txt</code></pre>
</section>
</section>
<section id="dataset-structure" class="level2">
<h2 class="anchored" data-anchor-id="dataset-structure">Dataset Structure</h2>
<p>The script expects the training data to be organized in a specific structure. The root directory contains subdirectories for different data categories (e.g., “Vel”, “Style”, “Fault”). Each subdirectory contains the input seismic data and target velocity models as <code>.npy</code> files.</p>
<p>The script automatically pairs <code>seis*.npy</code> with <code>vel*.npy</code> or <code>data*.npy</code> with <code>model*.npy</code>.</p>
<pre><code>/path/to/your/dataset/
├── Vel_Style_1/
│   ├── seis0.npy
│   ├── vel0.npy
│   ├── seis1.npy
│   └── vel1.npy
│
├── Fault_Models/
│   ├── data0.npy
│   ├── model0.npy
│   ├── data1.npy
│   └── model1.npy</code></pre>
</section>
<section id="configuration" class="level2">
<h2 class="anchored" data-anchor-id="configuration">Configuration</h2>
<p>All hyperparameters and settings are managed in the <code>Config</code> class within the script. Before running, update the paths and review the key parameters.</p>
</section>
<section id="how-to-run" class="level2">
<h2 class="anchored" data-anchor-id="how-to-run">How to Run</h2>
<section id="single-gpu-training" class="level3">
<h3 class="anchored" data-anchor-id="single-gpu-training">Single-GPU Training</h3>
<p>To run the training on a single GPU, simply execute the Python script:</p>
<pre><code>python fwi_swinunet_pipeline.py</code></pre>
</section>
<section id="multi-gpu-training-ddp" class="level3">
<h3 class="anchored" data-anchor-id="multi-gpu-training-ddp">Multi-GPU Training (DDP)</h3>
<p>For distributed training across multiple GPUs on a single node, use <code>torchrun</code>. This script will automatically detect the DDP environment and handle the setup.</p>
<pre><code># Replace NUM_GPUS with the number of GPUs you want to use (e.g., 4)
torchrun --nproc_per_node=NUM_GPUS fwi_swinunet_pipeline.py</code></pre>
</section>
</section>
<section id="outputs-and-results" class="level2">
<h2 class="anchored" data-anchor-id="outputs-and-results">Outputs and Results</h2>
<p>The script will create an output directory (specified by <code>OUTPUT_DIR</code>) containing the following:</p>
<ul>
<li><p>Log File: A detailed log of the entire training process.</p></li>
<li><p>Checkpoints:</p>
<ul>
<li><code>best_model_ema.pth</code>: The model state with the best validation score (based on EMA weights).</li>
<li><code>checkpoint_epoch_*.pth</code>: Periodic checkpoints saved every <code>CHECKPOINT_EVERY</code> epochs.</li>
</ul></li>
<li><p>TensorBoard Logs:</p>
<p>tensorboard –logdir /path/to/your/output_dir/tensorboard</p></li>
<li><p>Plots:</p>
<ul>
<li><code>*_metrics.png</code>: A comprehensive plot showing training/validation loss, MAE, learning rate, and gradient norm over epochs</li>
<li><code>*_predictions.png</code>: A visual comparison of ground truth velocity models, model predictions, and their absolute difference on a sample of the validation set.</li>
</ul></li>
<li><p>ONNX Model:</p>
<ul>
<li><code>*.onnx</code>: The final model exported to the ONNX format if <code>EXPORT_ONNX</code> is <code>True</code>.</li>
</ul></li>
</ul>
</section>
<section id="code-structure" class="level2">
<h2 class="anchored" data-anchor-id="code-structure">Code Structure</h2>
<p>The script is organized into logical, reusable components:</p>
<ul>
<li><p><code>Config</code>: A centralized class for all hyperparameters and settings.</p></li>
<li><p><code>DDPManager</code>: Handles the setup and cleanup of the distributed training environment.</p></li>
<li><p>Data and Preprocessing:</p>
<ul>
<li><code>FWIDataset</code>: Custom PyTorch Dataset for loading <code>.npy</code> files efficiently.</li>
<li><code>GPUBatchProcessor</code>: Performs all batch processing (normalization, augmentation) on the GPU to maximize throughput.</li>
</ul></li>
<li><p>Model Architecture (<code>MultiSourceUNetSwin</code>):</p>
<ul>
<li><code>SCSEBlock</code>: Squeeze-and-Channel-and-Spatial-Excitation attention module.</li>
<li><code>LearnedUpsample</code>: An upsampling block using <code>PixelShuffle</code> for higher-quality outputs.</li>
<li><code>EnhancedUNetDecoderBlock</code>: A sophisticated decoder block combining upsampling, skip connections, and residual blocks.</li>
</ul></li>
<li><p>Utilities (<code>ModelEMA</code>, <code>EarlyStopping</code>, <code>MetricsLogger</code>): Helper classes for EMA, early stopping, and logging.</p></li>
<li><p>Loss Function (<code>CombinedLoss</code>): A custom loss function combining Huber, Gradient, and Total Variation losses with support for class-based weighting.</p></li>
<li><p>Training and Validation Loops: The core <code>train_one_epoch</code> and <code>validate_one_epoch</code> functions.</p></li>
<li><p><code>main()</code>: The main execution function that orchestrates the entire pipeline.</p></li>
</ul>
</section>
<section id="results-and-evaluation" class="level2">
<h2 class="anchored" data-anchor-id="results-and-evaluation">Results and Evaluation</h2>
<p>The model trained for 34 out of 50 planned epochs before early stopping trig-gered. The total training duration was approximately 18.23 hours using efficient training technologues like DDP and AMP in 2x <code>H100</code> GPUs. The best valida-tion MAE was achieved at Epoch 29 with an overall (average) validation MAE of 63.27 m/s:</p>
<div id="tbl-best-model" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-best-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;1: Best EMA model
</figcaption>
<div aria-describedby="tbl-best-model-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<thead>
<tr class="header">
<th>Metric</th>
<th>Loss</th>
<th>MAE</th>
<th>Grad Norm</th>
<th>SSIM</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Train (Avg)</td>
<td>0.0375</td>
<td>66.69</td>
<td>0.08</td>
<td>-</td>
</tr>
<tr class="even">
<td>Val “Vel” Group</td>
<td>0.0141</td>
<td>43.07</td>
<td>-</td>
<td>0.8725</td>
</tr>
<tr class="odd">
<td>Val “Style” Group</td>
<td>0.0232</td>
<td>69.82</td>
<td>-</td>
<td>0.9188</td>
</tr>
<tr class="even">
<td>Val “Fault” Group</td>
<td>0.0253</td>
<td>76.94</td>
<td>-</td>
<td>0.8844</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>The model achieved its best overall validation MAE of 63.27 at Epoch 29. This significant reduction from an initial MAE of 308.34 in Epoch 1 demonstrates the effectiveness of the combined loss function, ro-bust architecture, and comprehensive augmentation strategy.</p>
<div id="tbl-epoch-metrics" class="quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-epoch-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Table&nbsp;2: Model training metrics across epochs
</figcaption>
<div aria-describedby="tbl-epoch-metrics-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<table class="caption-top table">
<colgroup>
<col style="width: 21%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
<col style="width: 11%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Metric</strong></th>
<th><strong>Epoch 1</strong></th>
<th><strong>Epoch 5</strong></th>
<th><strong>Epoch 10</strong></th>
<th><strong>Epoch 13</strong></th>
<th><strong>Epoch 20</strong></th>
<th><strong>Epoch 29</strong></th>
<th><strong>Epoch 3</strong>4</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Train Loss</td>
<td>0.1154</td>
<td>0.0659</td>
<td>0.0508</td>
<td>0.0462</td>
<td>0.0446</td>
<td>0.0375</td>
<td>0.0418</td>
</tr>
<tr class="even">
<td>Train MAE</td>
<td>439.84</td>
<td>157.19</td>
<td>102.60</td>
<td>88.68</td>
<td>84.61</td>
<td>66.69</td>
<td>77.88</td>
</tr>
<tr class="odd">
<td>Overall Val MAE</td>
<td>308.34</td>
<td>126.90</td>
<td>85.95</td>
<td>79.90</td>
<td>70.42</td>
<td><strong>63.27</strong></td>
<td>64.97</td>
</tr>
<tr class="even">
<td>Val Vel MAE</td>
<td>398.78</td>
<td>134.28</td>
<td>70.91</td>
<td>61.36</td>
<td>51.97</td>
<td>43.07</td>
<td>47.37</td>
</tr>
<tr class="odd">
<td>Val Style MAE</td>
<td>191.19</td>
<td>105.33</td>
<td>84.34</td>
<td>81.46</td>
<td>73.99</td>
<td>69.82</td>
<td>69.50</td>
</tr>
<tr class="even">
<td>Val Fault MAE</td>
<td>335.04</td>
<td>141.08</td>
<td>102.61</td>
<td>96.88</td>
<td>85.29</td>
<td>76.94</td>
<td>78.05</td>
</tr>
<tr class="odd">
<td>Val Vel SSIM</td>
<td>0.4973</td>
<td>0.7426</td>
<td>0.8196</td>
<td>0.8311</td>
<td>0.8583</td>
<td>0.8725</td>
<td>0.8714</td>
</tr>
<tr class="even">
<td>Val Style SSIM</td>
<td>0.7389</td>
<td>0.8542</td>
<td>0.8919</td>
<td>0.8966</td>
<td>0.9116</td>
<td>0.9188</td>
<td>0.9214</td>
</tr>
<tr class="odd">
<td>Val Fault SSIM</td>
<td>0.6343</td>
<td>0.8011</td>
<td>0.8500</td>
<td>0.8556</td>
<td>0.8756</td>
<td>0.8844</td>
<td>0.8864</td>
</tr>
</tbody>
</table>
</div>
</figure>
</div>
<p>Furthermore, we observed a consistent reduction in MAE across all three prediction tasks (Vel, Style, and Fault) and a corresponding increase in SSIM, indicating improved structural similarity between predictions and ground truth.</p>
<section id="predicted-velocity-maps" class="level3">
<h3 class="anchored" data-anchor-id="predicted-velocity-maps">Predicted Velocity Maps</h3>
<p>Across all displayed samples and groups, the predicted images closely resemble their corresponding actual counterparts. The model appears to maintain a good level of sharpness and detail in its predictions, especially for complex geological structures. The diversity of the samples shown (ranging from layered structures to more complex, chaotic patterns) suggests that the model has done a good job in generalizing the various geological scenarios within the dataset.</p>
<section id="vel-family" class="level4">
<h4 class="anchored" data-anchor-id="vel-family">“Vel” Family</h4>
<p>The “Vel” samples show excellent (best of the three) agreement between ground truth and prediction. The layered structures are accurately repro-duced, and the transitions between different velocity zones are smooth and well-defined.</p>
<p><img src="vel_predictions.png" class="img-fluid"></p>
</section>
<section id="style-family" class="level4">
<h4 class="anchored" data-anchor-id="style-family">“Style” Family</h4>
<p>The “Style” samples, which appear to represent more abstract or textural properties, are also well-predicted. The model captures the overall “flow” and patterns, even in intricate designs.</p>
<p><img src="style_predictions.png" class="img-fluid"></p>
</section>
<section id="fault-family" class="level4">
<h4 class="anchored" data-anchor-id="fault-family">“Fault” Family</h4>
<p>The “Fault” samples demonstrate the model’s ability to delineate complex fault structures. The predictions successfully capture the presence and general orientation of the faults, which are critical for geo-logical interpretation.</p>
<p><img src="fault_predictions.png" class="img-fluid"></p>
</section>
</section>
</section>
<section id="citation" class="level2">
<h2 class="anchored" data-anchor-id="citation">Citation</h2>
<p>If you use this code in your research, please cite:</p>
<pre><code>@misc{swinunet2025,
    author = {Gaurav Khanal},
    title = {Swin-UNet: Full Waveform Inversion with Swin Transformers},
    year = {2025},
    publisher = {GitHub},
    journal = {GitHub repository},
    howpublished = {\url{https://github.com/gk408829/Geophysical-Full-Waveform-Inversion}}
}</code></pre>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>